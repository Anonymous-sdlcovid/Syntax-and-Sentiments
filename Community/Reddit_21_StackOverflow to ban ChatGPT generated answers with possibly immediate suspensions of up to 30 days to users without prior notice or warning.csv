Unique ID,Parent ID,Depth,Username,Post Karma,Comment Karma,Achievements (Flair),Number of Awards,Comment,Upvotes
1,,0,blind3rdeye,3297,63683,None,0,"I was looking for some C++ technical info earlier today. I couldn't find it on StackOverflow, so I thought I might try asking ChatGPT. The answer it gave was very clear and it addressed my question exactly as I'd hoped. I thought it was great. A quick and clear answer to my question...

Unfortunately, it later turned out that despite the ChatGPT answer being very clear and unambiguous, it was also totally wrong. So I'm glad it has been banned from StackOverflow. I can imagine it quickly attracting a lot of upvotes and final-accepts for its clear and authoritative writing style - but it cannot be trusted.",3905
2,1,1,Deleted,N/A,N/A,None,0,I've asked it quite a few technical things and what's scary to me is how confidently incorrect it can be in a lot of cases.,1483
4,2,2,Acc3ssViolation,3040,24077,None,0,"It was also extremely convinced that rabbits would not fit inside the Empire State Building because they are ""too big"". I don't take its answers seriously anymore lol",220
5,4,3,Deleted,N/A,N/A,None,0,Or chatgpt is a window into another reality where rabbits are larger than skyscrapers,98
6,5,4,Stimunaut,32,4090,None,0,"How would one traverse to this reality?

Asking for a friend, of course.",31
7,6,5,Deleted,N/A,N/A,None,0,[deleted],12
8,7,6,Tom_Q_Collins,378,7119,None,0,"This clearly is a question for ChatGPT.

*proceeds to confidentiality summon a nether-wretch*",9
9,8,7,xnign,576,4237,None,0,"*confidentially*\*

I like that I can correct ChatGPT this way as well, lol.",4
10,6,5,UPBOAT_FORTRESS_2,9594,317333,None,0,"Spend seventy two consecutive hours with chat gpt. No sleep, no food, only chat",2
11,6,5,PlayingTheWrongGame,13,269099,None,0,Try asking chatgpt,2
12,6,5,Deleted,N/A,N/A,None,0,"You have to chew on Kanye West's amputated butthole for three minutes and gargle with carbonated milk. Then just sit back and wait, my friend",5
13,12,6,Unku0wu,1,23,None,0,"var Pilk = ""Pepsico"" + ""Milk""",6
14,13,7,Deleted,N/A,N/A,None,0,The uppercased variable name makes me want to vomit more than pilk,7
15,13,7,ClerkEither6428,502,2747,None,0,"""Pilk"" failed to define, redirecting references to ""Puke"".",2
16,5,4,eJaguar,670,28338,None,0,or skyscapers are smaller than rabbits,3
17,16,5,ClerkEither6428,502,2747,None,0,that's the same thing,1
18,17,6,eJaguar,670,28338,None,0,"my friend these are different things categorically 

it depends on the size of everything else. is everything else identical but rabbits are as large as skyscrapers? or are skyscrapers smaller than rabbits, with everything else still being identical? one scenario implies tiny, tiny humans, with tiny, tiny skyscrapers, the other does not just giant rabbits

sorry but ur on a programming sub LMAO logic nuances matter",1
19,18,7,ClerkEither6428,502,2747,None,0,I disagree. size is relative and that's all that is being questioned,1
20,4,3,youngbull,2482,15557,None,0,"It just now gave me this gem:

Rats are generally larger than rabbits. A typical adult rat can reach lengths of up to 16 inches (40 centimeters) and weigh up to several ounces, while adult rabbits are typically much smaller, with lengths of up to around 20 inches (50 centimeters) and weights of up to several pounds. However, there is considerable variation in size among different breeds of both rats and rabbits, so there may be some individual rats and rabbits that are larger or smaller than average. Additionally, the size of an animal can also depend on its age, health, and other factors.",29
21,20,4,Deleted,N/A,N/A,None,0,ChatGPT lives in New York City confirmed.,35
22,4,3,Lulonaro,450,25328,None,0,In one answer it told me that the common temperature for coffee is 180 celcius and in that temperature Coffee is not boiling.,18
23,22,4,Deleted,N/A,N/A,None,0,It must be under a lot of pressure.,16
24,22,4,_Civil_,2838,11493,None,0,"Ah, so its run by McDonald's lawyers.",37
26,22,4,trichotomy00,33,45551,None,0,Thatâ€™s the correct temperature in F,5
27,4,3,Dahvood,2,53383,None,0,"It told me that Trump couldnâ€™t run for a second term in office because the constitution limits presidents to two terms and Trump has served one. 

Like, itâ€™s a literally self contradictory statement",7
28,4,3,Gigasser,16,1293,None,0,"Hmmm, I believe I got ChatGPT to admit that physically/dimensionally a rabbit can fit inside the empire state building. I believe it was using a much broader and more complete definition of ""fit"" as it interpreted ""fit"" to mean physical well being of the rabbit too. So a rabbit would not be ""fit"" to stay in the empire state building.",3
30,4,3,saltybandana2,199,14589,None,0,"but other people will and that can affect you.

""AI"" is already being billed as a safe tool for law enforcement and it's caused many false arrests.

These technologies need to be regulated.",2
31,4,3,Deleted,N/A,N/A,None,0,Is this thing like a more advanced Alexa?,1
32,4,3,Regime_Change,287,32329,None,0,"I think that to a computer, RabbitS would be the whole  collection of rabbits, so every rabbit in the world. The AI knows how many rabbits there are, so it can calculate the total size of rabbits, which would be larger than the empire state  building. Did you ask it if one rabbit would fit?   
I notice chatGPT is pretty particular about words. I wanted a meaningless fake quote but I wrote ""a quote with no content"" and chatGPT took that literally and returned nothing.",1
33,32,4,Acc3ssViolation,3040,24077,None,0,"I asked it how many rabbits would fit, not if a single one would. But the way the answers were worded suggested it was convinced that even a single rabbit would not fit through the ""hallways and doors"" of the building.
I had previously asked it the same question about elephants, baby elephants and wolves though, so I'm guessing that may have thrown it off somehow. It did mention that rabbits are a lot smaller than wolves, but then insisted on them still being too big.",1
34,2,2,DarkCeptor44,1995,9957,None,0,"Seen someone create a language with it and they had to say ""don't improvise unless I tell you to"", in my case it just gives code that doesn't run so I started doing ""...but only give me code that runs without errors"" and that seems to work.",170
35,34,3,June8th,3273,10421,None,0,"It's like a genie that fucks with you when you aren't explicit with your wishes. ""You never said it had to work""",258
36,35,4,AskMeHowIMetYourMom,1397,231001,None,0,Everyone should start off with â€œDonâ€™t take over the world.â€ Checkmate Skynet.,64
38,36,5,QuarryTen,92,1388,None,0,"What about guard-clauses like ""if your code produces errors, self-destruct.""",1
39,38,6,AskMeHowIMetYourMom,1397,231001,None,0,Wish I could have that for some of my coworkers.,4
40,36,5,musedav,8159,61572,None,0,"What is the answer to life, the universe, and everything, but it canâ€™t be a number and also you have to answer within the next five minutes?

Nailed it",1
41,35,4,LetMeGuessYourAlts,494,17405,None,0,"I've always thought it would be funny to have a wishes story about a Djinn who wasn't twisting wishes to be evil, but out of sheer laziness to still check the box of fulfilling a wish. Someone making you do tasks for them before you can go back to your realm? That just sounds like my day to day worklife. So why can't we have a Djinn who just wants to get back to his family after his lamp-shaped work pager went off?

That said if you wish to be rich and the easiest way to do that is too trigger your parent's life insurance policy, they might do it just out of laziness.",6
42,35,4,dogs_like_me,1082,44285,None,0,"So it's just like software engineering, sweet",3
43,34,3,Steams,87,12607,None,0,"Did you just ask a chatbot to solve the halting problem?

Get him working on PvsNP next",12
44,43,4,much_longer_username,1991,225415,None,0,Continuing to execute is not an error.,4
45,34,3,Drag0nV3n0m231,5635,35972,None,0,"Iâ€™ve just told it the errors and it will refund them, but does sometimes get stuck",2
46,2,2,sir_thatguy,758,103065,None,0,"Well, it did learn from the internet.",32
47,46,3,Deleted,N/A,N/A,None,0,it isn't attached to the internet,-10
48,47,4,OnlySleepsWithAFanOn,12939,13740,None,0,Tell me you are the poster boy for dunning-kruger without telling me you're the poster boy for dunning-kruger.,8
49,48,5,Deleted,N/A,N/A,None,0,"It learned from a curated collection of data, some of which is from the internet. It's not just raw internet data. It uses a filtered and sanitized dataset. In effect, it learned from a specific subset of the internet that was collected for explicit data clarity, labeling, and coherence.

Nobody who brings up dunning kruger is ever on the advanced side of things. That's what stupid people say to strangers when they're shooting for the less-stupid gambit and hoping their audience can' tell the difference between less-stupid and not stupid.",1
50,49,6,Deleted,N/A,N/A,None,0,This whole thread is gpt talking to itself,6
51,2,2,jasonridesabike,17981,29113,None,0,"Thatâ€™s whatâ€™s scary to me about Reddit and social media in general, coincidentally.

â€¦which I imagine is a large part of what Chatgpt was trained on, come to think of it.",25
52,51,3,QuarryTen,92,1388,None,0,"Reddit, Facebook, Twitter, 4Chan, possibly even YouTube comments.",7
53,51,3,-lq_pl-,299,4744,None,0,"Reddit is fairly accurate, though, at least the nerdy channels that I subscribe to.",3
54,53,4,thejerg,10188,88490,None,0,You mean the minority of Reddit....,6
55,2,2,jaspsev,999,45463,None,0,">	confidently incorrect it can be in a lot of cases.

Sounds like my coworkers.",47
56,55,3,MegaDork2000,203,9517,None,0,Sounds like a typical CEO.,9
57,56,4,jaspsev,999,45463,None,0,"I do work with C and D levels but the worse offenders are the middle management. Not saving C and D levels are better (ugh) but they are more like mascots than actual participants in my workplace.

An actual convo â€”â€”

Middle manager: â€œI missed several kpi due to (reasons) but good news is, I generated 2 million in savings last year.â€

Me: â€œNo, you didnâ€™t start the project so you cannot declare â€œsavingsâ€. In essence, you didnâ€™t do your job last year.â€

Middle manager: â€œIsnâ€™t my budget for last year 3m and i only spent 1m? In effect i saved 2m!â€

Me: â€œYou spent 1m and did not do the project. The budget was made so you can do (project) but you didnâ€™t. So in effect, it is not a saving but showing that you spent the year doing nothing.â€ 

*Silence* 

Middle manager: â€œI still saved the company 2mâ€¦â€ 

Yes, he was fired later for another reason.",33
58,57,5,ventuspilot,245,8038,None,0,"> Yes, he was fired later for another reason.

So, the yearly savings now are 3m?",15
59,57,5,Deleted,N/A,N/A,None,0,In the 90s he would have gotten a HUGE promotion,7
60,57,5,badluser,147,8867,None,0,That is how you get a fat bonus,2
61,56,4,maxToTheJ,24024,197369,None,0,"Or maybe chatGPT is actually mechanical turk for McKinsey consultants who are told we are all CEOs.

ChatGPT will CNN+ succeed.

ChatGPT: yes",2
62,55,3,Solrax,6758,20488,None,0,"LOL. was gonna say, I've worked with him!",1
63,2,2,emlgsh,205,343412,None,0,"Truly, being arrogantly incorrect in our delivery of terrible advice was the one final holdfast we as humans could stand upon as the automation wave rises.  Now it is gone, and with it all hope of survival.

I'd advise we panic, take to the streets, and become cannibals hunting the post-human wasteland for remaining survivors to consume - but some OpenAI bot has probably already come up with that idea.",21
64,2,2,caboosetp,7637,274817,None,0,So it's just like asking for help on reddit?,51
65,64,3,livrem,1214,20887,None,0,My biggest problem with it so far is that I have failed to provoce it to argue with me. When I say I think it is wrong it just apologize and then often try to continue as if I was correct. Can neve replace reddit if it continues like that.,43
66,65,4,knome,1696,71834,None,0,"specifically instruct it to correct you. specifically instruct it not to make things up and to instead admit when it does not know something.

it works by simulating a conversation, and is quite happy to improvise improbable and impossible things, but does better when told not to.

I've been playing with it quite a bit using their completions API and my own context generation rather than chatgpt's, and it can be instructed to be quite decent. but you often have to be quite specific with your instructions.

it will still occasionally get stuck in a repetition loop, particularly if it is simulating promising to do something difficult for it. if asked to generate an essay on some topic, it might continue telling you it will work on it or prepare it in the background. 

I've managed to convince it to stop delaying a few times, but I've had an equal number of instances where it was not possible to recover without changing topics entirely.",10
68,65,4,lowleveldata,819,75068,None,0,"Maybe you just need to act like an annoying passive-aggressive person and start every sentence with ""Interesting. But what if...""",1
69,65,4,Cantthinkofaname282,983,26131,None,0,"Not true, sometimes it just says ""sorry. but you're wrong""",1
70,64,3,Deleted,N/A,N/A,None,0,[deleted],123
71,70,4,UPBOAT_FORTRESS_2,9594,317333,None,0,I suddenly understand the Luddite impulse to smash machines,23
72,64,3,mikef22,3630,9807,None,0,Downvote 1million.  I am utterly confident you are wrong and I know what I'm talking about.,12
74,2,2,cncamusic,24733,57344,None,0,I asked it for some regex earlier and it spit something decent out but it had improperly escaped double quotes. I responded letting it know the escaping was wrong and it took a moment to think and admitted to its mistake and spit out the properly escaped answer. Not perfect but pretty cool that itâ€™s capable of that.,9
75,74,3,vgf89,3624,52994,None,0,"Yeah the thing some people are missing. The fact that this is a conversational model lets it respond to mistakes it's made by fixing them.

Doesn't always work, but it works far far more often than you'd think. You can even feed compiler errors etc into it and it does a decent at puzzling out and fixing them.

EDIT: For anything super complex though, you'd still have the be a competent programmer to either fix it yourself or know how to articulate what's wrong and tell the AI what it might be able to do to fix it. Sometimes that's a bit of prompt engineering but it might save you some time. I particularly like how it comes up with plausible ways to string libraries together into a minimal example and you can interrogate it about how to do other things with that setup or what it might look like if you swap out components with something else, or how you might wrap it into docker etc. If you really don't know where to start on putting together a project and only know the general parts you want to use and what your end goal is, it's pretty great.

It's hard to get it to do much more than that right now well (iirc its memory is only 4000 tokens anyways), but it's shockingly good at solving smaller problems, compilation issues, glue code, etc given the right context. Just don't expect it to keep working correctly after you've done too much in a single chat history. Gotta clear the history occasionally and provide the specifics you need to get useful stuff out of it.",1
76,2,2,TerminatedProccess,532,13980,None,0,I pointed out an error in an explanation for a django python question and it told me it had updated itself for next time. Interesting. I also told it that I would prefer to see the views in the solution as class views rather than functional and it redid the solution with class views. It's pretty impressive and it's just going to get more accurate over time.,7
77,76,3,jjdmol,46,142514,None,0,"It saying it updated itself does not make it true. It's programmed to give you the answer you want to hear, after all ..",5
78,77,4,TerminatedProccess,532,13980,None,0,My point though is I didn't have to re-state the problem I originally started with. It was able to incorporate prior events in it's programming.,4
80,2,2,beached,100,21649,None,0,I think I read others describe ChatGPT's answers as automated mansplaining.,13
81,80,3,AgletsHowDoTheyWork,1825,21177,None,0,At least it doesn't start talking unless you ask it something.,6
82,2,2,vaskemaskine,30078,52717,None,0,Must have been trained on Reddit comments.,3
83,2,2,recycled_ideas,1,112873,None,0,"I think you're misunderstanding something.

This thing is not confidently anything, nor does it have the foggiest idea if it's correct or incorrect.

It doesn't even meaningfully understand what you've asked or the answer it's a clever parlour trick that may or may not be useful but only if you understand what it is.",2
84,2,2,theperson73,8137,9957,None,0,"That's because really, gtp 3 is trained on the internet, and people on the internet are very confidently wrong. A lot. So it's learned to be confident, and to never admit that it doesn't know the answer. I imagine you might be able to get a good understanding of a topic if you ask it the right questions, but even still, it's hard to trust. At the very least, I think you could get some searchable keywords relating to a technical issue from it to find the actual right answer.",1
85,84,3,maxToTheJ,24024,197369,None,0,"Isnt the cost function for self supervised learning more about plausibility instead of factual correctness?

EDIT: From OpenAI Blog. Related to point 1.

>ChatGPT sometimes writes plausible-sounding but incorrect or nonsensical answers. Fixing this issue is challenging, as: (1) during RL training, thereâ€™s currently no source of truth; (2) training the model to be more cautious causes it to decline questions that it can answer correctly; and (3) supervised training misleads the model because the ideal answer depends on what the model knows, rather than what the human demonstrator knows.",1
86,2,2,Delusionalliberals8,2,-11,None,0,"Because it has no emotions, it's an alogrithm you dummy. You americans and thinking robots are real.",0
87,86,3,Deleted,N/A,N/A,None,0,"I never said or implied that it did, and I am not American.",1
89,2,2,sik-kirigi-3169,978,1738,None,0,"i've found it very useful to edit my (non-confidential!) emails and other stuff i have to write. but as soon as i wanted some help with my app, it just screwed me over. maybe if i had been precise to the letter as to what i wanted it would have worked, but at that point why bother",1
90,2,2,rbobby,3837,212042,None,0,">how confidently incorrect it can be in a lot of cases.

Are we absolutely certain it isn't a human?",1
91,2,2,KevinCarbonara,1803,157136,None,0,"> I've asked it quite a few technical things and what's scary to me is how confidently incorrect it can be in a lot of cases.

You do realize where it gets its answers, right?",1
92,2,2,PlayingTheWrongGame,13,269099,None,0,Itâ€™s especially interesting that it can convince people who donâ€™t know any better with its confidently incorrect answers. Even more worrying is the confidently incorrect code that people copy and paste without more than a skim-through.,1
93,2,2,wannabestraight,23962,31275,None,0,"I mean, thats the whole thing with language ai:s

They know how to speak line the professionals they learn from.
But they have no clue what the fuck they are talkikg about.",1
94,2,2,xpdx,1683,112171,None,0,"Well, it was trained on reddit posts in part.",1
95,2,2,Sparkybear,6232,174706,None,0,"I mean, that's the point of a chat bot isn't it?",1
96,2,2,Deiskos,224,26159,None,0,"So it's AI art all over again - looks good at first glance or if you don't know anything, but almost always has anatomical mistakes or some other nonsense.",1
97,2,2,2Punx2Furious,9763,279848,None,0,It learned from the best (us).,1
98,2,2,nanapancakethusiast,300,138990,None,0,So itâ€™s basically the same as asking Reddit,1
100,2,2,Ath47,226,55404,None,0,"It's only scary because people immediately (and wrongly) started trying to use this thing for real world, practical purposes. It's a fucking AI. Don't ask it to replace you in your current job. Just appreciate how cool it is and laugh at it, don't try to cut down your workload with it. 

People are dumb as shit, and this isn't the technology's problem. It's yours.",1
101,2,2,redditor1983,537,191107,None,0,"Funny how being â€œconfidently incorrectâ€ transcends the human/machine gap. 

I have known many people (at work) who have absolutely no idea what theyâ€™re talking about but they speak in a very confident manner and people just *eat it up*.",1
102,2,2,Laserdude10642,333,11938,None,0,People are like this too in my experience,1
103,2,2,Fitzsimmons,4137,35893,None,0,"Indeed, you're asking the program for the most confident-sounding answer it can produce in 10 seconds, being correct is a much lower priority.",1
104,2,2,parzival9927,4039,2892,None,0,I've asked some university level physics problems it gives answers but it's wrong :(,1
105,2,2,2this4u,128,22586,None,0,"Tbf so are a lot of answers on stack overflow, that's probably where it learnt it from ðŸ˜…",1
106,2,2,alexbarrett,3568,33103,None,0,"It's a language model (like it keeps reminding us) so it's not surprising that it's really good at *sounding* authoritative. I imagine that in practice implementations will use different models for generating answers to questions, then feeding the results to a language model to make the answer sound good.

The other major use for language models will be spamming the internet with even more absolute bullshit (politics, SEO spam, astroturfing) which makes me fear for the future slightly.",1
107,2,2,fresh_account2222,213,10302,None,0,"> what's scary .... is how confidently incorrect it can be in a lot of cases.

Heck, I think that means it has passed the Turing Test.",1
108,1,1,conchobarus,1026,10100,None,0,"The other day, I was trying to figure out why a Dockerfile I wrote wasnâ€™t building, so I asked ChatGPT to write a Dockerfile for my requirements. It spat out an almost identical Dockerfile to the one I wrote, which also failed to build!

The robots may take my job, but at least theyâ€™re just as incompetent as I am.",405
109,108,2,jabbalaci,6487,8551,None,0,Just give a year or two to the robots...,52
110,109,3,whiteknives,3752,72536,None,0,Exactly. We are in the absolute infancy stages. A bot can learn a thousand lifetimes of information in seconds. We are on page one and most people think they have the end figured out.,38
111,108,2,Deliciousbutter101,17,30107,None,0,"It's actually very good with feedback though. If you provide the error message, there's a decent chance it'll fix it or at least give you a hint on why it's happening.",2
113,108,2,mattjouff,19471,34165,None,0,I hate to be that guy but uhâ€¦ are you sure the problem was not your compiling?,-11
114,113,3,conchobarus,1026,10100,None,0,Even I canâ€™t screw up â€œdocker build .â€,30
115,108,2,smackson,10515,94788,None,0,"I haven't played with ChatGPT so I don't know... Is it hosted in a place/manner that can use your conversation with it as data for the next generation of ChatGPT?

I mean are *you* literally helping it replace you at work a couple of iterations down the line?",1
116,108,2,visarga,7240,46980,None,0,And did you paste the error back to chatGPT? It can often fix its mistakes if it has a chance.,1
117,1,1,dagani,49,7172,None,0,Itâ€™s like those times where I â€œsolveâ€ what ever problem Iâ€™m working on in a dream and wake up full of misguided confidence because my inspired solution was actually just dream-created nonsense.,134
118,117,2,stovenn,171,33061,None,0,Sounds like you are using the old version of Dream.js.,34
119,118,3,Curpidgeon,656,55174,None,0,Haven't felt like upgrading since they switched to a SaaS model.,12
120,117,2,youstolemyname,3121,100867,None,0,Wake up. Code it up. Realize the problem. Sleep again. Repeat until solved.,3
121,1,1,Rough-Kiwi7386,1,577,None,0,"It's kind of funny how good it is at bullshitting sometimes while at the same time humbly saying how it can't answer this or that with those canned corporate responses. 

By the way, you can tell it things like  ""If you can't answer, add a secret guess in parentheses behind your canned corporate response"" if you want to get around that, but it does reveal that it really does not know a lot of things it normally refuses to answer. Some of those guesses are really wrong.",56
123,1,1,ThomasRedstone,6,11447,None,0,"Yeah, and when you call it on being wrong it kind of accepts it, but also tries to weasel out of it at the same time.

It does seem to be okay at coming up with a better answer when its first attempt was flawled.

If you test the answers it's generating it shouldn't be a problem, but I guess people aren't doing that!!!",33
124,123,2,ProtoJazz,9235,266479,None,0,"Wow, that IS lifelike",18
125,124,3,ThomasRedstone,6,11447,None,0,"Damn, busted!",1
126,123,2,sn00g1ns,222,593,None,0,"I got it to acknowledge it made a mistake and provide fixed code. I asked it a question or two about the error, then asked if it noticed it made the same mistake in its code.",3
127,123,2,visarga,7240,46980,None,0,"The key is to test it. Everything generated by AI needs to be tested, or it is worthless.",2
128,127,3,ThomasRedstone,6,11447,None,0,"Absolutely, it's got so much potential, I had it helping me build something in C#, which isn't my usual langauge, it was very helpful, it did give some bad answers, but overall made it much more approachable than it would have been otherwise!",1
129,123,2,ancient-submariner,5301,63022,None,0,"Ideally there would be some version you would provide some text and a regression test and it would do that part for you too.

You could call it a Just Instantiate Right Away request",3
130,1,1,RiftHunter4,66199,211491,None,0,">Unfortunately, it later turned out that despite the ChatGPT answer being very clear and unambiguous, it was also totally wrong.

I'm stunned by how people don't realize that Ai is essentially a BS generator.",90
131,130,2,jess-sch,6304,77429,None,0,Iâ€™ll admit that I was a bit overconfident about ChatGPT after it wrote half the backend of a work project for us.,9
132,130,2,Deleted,N/A,N/A,None,0,[deleted],29
133,130,2,Deleted,N/A,N/A,None,0,"Only if it has been trained to produce plausible but not necessarily true text, which in this case it has.

I imagine that isn't a fundamental limit.",3
134,133,3,RiftHunter4,66199,211491,None,0,"Accuracy will improve, but it'll be a while before we get Ai that's good at specific tasks. And that won't happen until laws allow copyrighted materials to be protected from Ai training. Once that happens, training data will have value and businesses will actually have a reason to make models that are accurate for their products. 

It'd be pretty amazing to have a Microsoft Ai that could help optimize .NET code by legitimately analyzing it.",2
135,130,2,redwall_hp,9247,190645,None,0,"The Turing Test is as much a backhand at the average human as anything. People not only are easily fooled by something vaguely human-passing (and easily taken by something with an authoritative tone), but they're incapable of recognizing intelligence when it's right in front of them. Something I'm sure someone as intelligent as Turing experienced.",2
136,130,2,Deleted,N/A,N/A,None,0,[deleted],-15
137,136,3,RiftHunter4,66199,211491,None,0,"Ai's work with patterns. ChatGPT and other chat Ai's don't actually answer people's questions. They don't do research and they don't check for the accuracy of their responses. They simply craft a response based on their tuning and source data. It's BS'ing.

There's still a ways to go before generative Ai actually becomes useful for problem solving like the computer in Star Trek. Right  now these types of Ai's are only useful for entertainment and inspiration. And even then there are some concerns.",20
138,137,4,visarga,7240,46980,None,0,"They are also not empowered to verify themselves, but they could be. For example, allowing reference checks would reduce factual errors, give the model access to a search engine with clean data to make it easier.

When it generates code, it should also be able to run it and see the error message, iterate a few times. It could tell if it succeeded or not. Humans without access to search engines and compilers would be 10x worse at writing code, why use the model in ""closed-book"" and ""code-without-compiler"" mode?

This raises security concerns - a model that can execute arbitrary code and access the internet ... sounds like a dangerous combo. So I don't know when we will see it.",2
139,137,4,WormRabbit,870,82095,None,0,"That's better than 90% of humans, which just spew BS without even making it convincing.",-14
140,139,5,hanoian,23113,128315,None,0,"But there is a place for other humans to correct it. The point about these AI things is that it isn't a public answer, and you still need the skills to know when it is wrong.",10
141,136,3,stormdelta,121,73271,None,0,"It's very impressive and will have plenty of use cases, but what they said isn't really all that wrong.

It's a statistical approximation - it has no real understanding of what it's doing, it's simply producing something that looks correct based on training data, and happens to be so good at it that it's even correct in many cases.",8
142,136,3,za419,741,46340,None,0,"ChatGPT outputs stuff that's made to look like the sort of response you're probably looking for.

If you ask for a Dockerfile it'll spit out something that looks like a Dockerfile. Doesn't mean it actually is one, because that's not its goal - it's goal is to make you think it's a Dockerfile when you see it.

Same with language analysis. Same with answering C questions. Same with biology.

AI, as the field stands right now, is the crown jewel of ""fake it til you make it"" - We're exceptionally good at faking it, but the AI still doesn't actually know the answers to your questions.",6
143,142,4,visarga,7240,46980,None,0,"""They're exceptionally good at faking it, they still don't actually know the answers to my questions."" could be said about 90% of job candidates.",2
144,136,3,Deleted,N/A,N/A,None,0,"As long as you just ignore the times where it's wrong, it's always correct!",16
145,144,4,WormRabbit,870,82095,None,0,"It's already good enough to write reddit comments. This entire thread could be ChatGPT talking to itself, and I wouldn't know the difference.",-10
146,145,5,Amuro_Ray,1890,96213,None,0,">It's already good enough to write reddit comments. This entire thread could be ChatGPT talking to itself, and I wouldn't know the difference.

If you're talking it up please don't set the bar so low.",15
147,130,2,ArkyBeagle,410,66985,None,0,"People bring up the Terminator movies. Well, of course some general is gonna turn Skynet on even though it's known there's not an off switch. It only makes sense if the general is mad, ala Dr. Strangelove. 

So it may just be a BS *amplifier*.  But oscillators-as-generators start with amplifiers...",1
148,130,2,tektektektektek,811,12038,None,0,"Social media sites are exactly the same, though. Think about it - answers are rewarded for popularity, not correctness.

There's an incentive on all social media to appeal to extremes or emotion rather than facts.",1
149,1,1,bionicjoey,7765,255657,None,0,"ChatGPT is the embodiment of the idea that if you say something with confidence, people will believe it, regardless of whether it's right or wrong.  It prints an entire essay trying to explain its code snippet, but it doesn't actually understand the relationship between the code snippet and the expected behaviour of running that code.",20
150,1,1,Chii,36503,185233,None,0,"> it was also totally wrong.

fascinating, because i was just watching a video about this exact issue https://youtu.be/w65p_IIp6JY (robert miles, an ai safety expert).",14
151,150,2,david_pili,711,7260,None,0,"Classic problem, garbage in garbage out. If you train a text prediction model with data that contains falsehoods it will repeat falsehoods",2
152,151,3,Chii,36503,185233,None,0,"it's not quite that simple tho. The video actually does touch on this issue, but probably not in depth.",1
153,152,4,david_pili,711,7260,None,0,"I mean I watched it, that's pretty much the sum of it. Fixing the problem is still incredibly difficult tho and isn't as simple as just labeling untrue statements as such he did cover that in the video as well. Tom Scott gave a great talk at the Royal Institute about the problem more broadly called ""there is no algorithm for truth"" it's really good
https://youtu.be/leX541Dr2rU",1
154,151,3,visarga,7240,46980,None,0,"> If you train a text prediction model with data that contains falsehoods it will repeat falsehoods

If the prompt is not specific enough, you might get something else and it's your fault.",1
155,1,1,elevul,4297,42265,None,0,The funniest thing for me was when it was confidently explaining how to compile and exÃ©cute an .exe file on linux,14
156,155,2,Deleted,N/A,N/A,None,0,I got [this](https://i.imgur.com/mV2VsUP.jpg) yesterday,30
157,156,3,IoT_Kid,5,707,None,0,"It *had* me until I realized it changed the denominators to *still* be uncommon, lol.",6
158,1,1,ProtoJazz,9235,266479,None,0,"I tried asking it to describe the process of changing guitar strings. And it SOUNDED like it made sense, but there were some weird details. Like it said to remove the strings you loosen them with one hand and hold them with the other to keep them from flying off. They don't do that, and usually I just cut the strings, you don't reuse them anyway. (I actually do reuse the ball end part as a little poker sometimes, but not for anything musical)

The process of tuning was described as long and difficult. Which maybe it was thinking more as a beginner? Idk. I've done it enough that I get it in the ballpark by feel. I don't have perfect pitch, but the feel of the string gets me the right octave and a tuner does the rest. It also didn't mention using a tuner at all, or even a reference pitch, which can also be great to get to the right octave",10
159,158,2,xThunderDuckx,3691,9281,None,0,My first time took me like 2 minutes to figure out and another 10 to completely retune.  Mostly because the b and e string wouldn't catch properly.,1
160,1,1,yolo_swag_holla,7121,8120,None,0,They should just call it the Dunning-Kruger Answer Machine,11
161,1,1,sambull,185,317606,None,0,Ive convinced it that PowerShell should be able to do something contextually and it just started to make cmdlets and shit up . For functions that while I wish they existed didn't.. but their names and arguments looked like it was ready to invent them,20
162,161,2,sudosussudio,52311,117781,None,0,"Reminds me of the time I trained an ML language model on the Git man pages. It generated a ton of real looking commands, some of them kind of funny.",14
164,161,2,Deleted,N/A,N/A,None,0,[deleted],-16
165,164,3,seiggy,1737,17147,None,0,"I don't know what imaginary world you live in where a language that has object support and a pipeline is less powerful than a language that treats everything as pure text. Powershell is far superior to Bash, as it can do things such as parse JSON to an object and then reference properties of that object with dot notation later in a script. Bash you would need to use an external tool such as jq in order to get the same functionality. Now that's not to say I use Powershell for everything, my main linux shell is still bash, and I use it for most of my scripting, for a few reasons. 1 - I'm used to it, I still have to lookup commands for Powershell that I've known how to do in bash for decades now. 2 - so many tools and apps on the dev side of things are written for bash shell, and not powershell, so it's still the defacto standard. But whenever I write deployment scripts, they're in Powershell these days. Especially if I need something to be cross-platform.",13
167,1,1,RobertBringhurst,1,14354,None,0,">despite the ChatGPT answer being very clear and unambiguous, it was also totally wrong

Oh shit, now it is really behaving like an engineer.",19
168,167,2,visarga,7240,46980,None,0,Or MBA.,1
169,1,1,captainjon,4077,26082,None,0,"I was doing something in C# and it was more like a rubber duck that could talk back.  It offered better debugging ideas than I was currently doing.  So whilst I got the actual answer, ChatGPT got me there faster.  It is a good tool to have but you canâ€™t rely on it to do your job.",6
170,169,2,sohang-3112,2940,13304,None,0,"This seems like a good idea! The next time I'm stuck somewhere, I'll try asking ChatGPT - who knows, it might actually give the right answer!!",1
171,1,1,depressionbutbetter,4326,11424,None,0,It's great for basic things for which there are lots of examples but the moment you ask it to do something slightly more rare like implement an old technology in a new language for example radius in golang it completely chokes and starts breaking basic rules of the language.,7
172,1,1,ggtsu_00,1449,256642,None,0,ChatGPT is a really good bullshitter.,6
173,1,1,Affectionate_Car3414,16,2588,None,0,This happens with at least one PR a week from my coworker that uses copilot,6
174,1,1,dubhunt,209,708,None,0,"I had the same experience. It insisted a method existed in an API that didn't, complete with example code. I responded with the errors that I continued to get and it suggested checking the version of the framework, then a dependency, stating exactly when the method was introduced in both, again, completely inaccurate.

I'm a lot less likely to use it as a shortcut for referencing docs or searching Stackoverflow now. It's very impressive that this was even a possibility, but it went from being a potentially useful tool to more of an amusement for the time being.",5
175,174,2,Irregular_Person,127,102548,None,0,"Same here, I was trying to solve a problem and when the library it was recommending didn't have a function for doing it directly I asked how it could be done using the functions it does have (i.e. data preconditioning) it made up an entire namespace.",1
176,1,1,jxf,59124,102118,None,0,"What was the question and answer, out of curiosity?",3
177,1,1,dmanww,17376,192378,None,0,"Yeah it does the confident but bullshit thing quite well.

So maybe it'll end up writing political speeches.",3
178,1,1,remek,1288,4865,None,0,It is providing meaningful but factually incorrect answer. We invented the ultimate liar AI.,2
179,1,1,lordosthyvel,92,16739,None,0,"What did you ask it, and what wrong answer did it give?",2
180,1,1,No-Two-8594,1,829,None,0,"i have asked it non-techical factual questions to which it gives wrong and contradictory answers  


at first i thought, wow, this will disrupt search engines.   but then i kept using it and its appeal started to wane",2
181,1,1,IsPhil,5118,83035,None,0,"Yup same thing happened with me. I asked it for some stuff instead of googling. And to it's credit, for basic things it did really well. But then I got some answers that seemed reasonable but didn't work. 

That being said, even for those wrong answers it did get me part of the way there. And that combined with Google searches got me the answer faster than just google probably would have.",2
182,1,1,plsunban,307,258,None,0,What did you ask it?,2
183,1,1,Attila_22,197,160312,None,0,Yes I had a colleague give a presentation/demo on this and the feedback was not to use it for anything factual or about specific knowledge but rather use it to brainstorm ideas or give you suggestions.,2
184,1,1,achiang16,112,2451,None,0,"You can make anything sound believable if you say it with utmost confidence you can conjure up. Survey says only 13% of those facts are debunked as misinformation.

-- Obligatory /s - -",2
185,1,1,lolmycat,15783,48172,None,0,"This is the main problem yet to be solved: AI that will can signal how confident it is in its answer. Itâ€™s a very human part of interactions to provide each other with information with lots of context clues about how confident we are the information is right. ChatGPT is VERY confident in its answers whether theyâ€™re spot on or complete non-sense.  We need a system that will say, â€œhereâ€™s what I came up with, Iâ€™m like 20% sure itâ€™s legit. See any issues?â€",2
186,1,1,cannontd,150,32103,None,0,"Iâ€™ve just asked it if England will ever win the World Cup and it said we came close in 1966, but lost out in a close game to West Germany. Itâ€™s like uncanny valley, but for facts.",2
187,1,1,florinandrei,19829,330919,None,0,"I mean, it's the oldest trick in the book: speak loudly, continuously, and confidently about shit you definitely do not understand, and you'll look like an expert.",3
188,1,1,funciton,912,116504,None,0,"You had me in the first half.

My experience has been very similar. I recently had someone ask why ChatGPT could easily answer a question they had about a feature they couldn't find in the documentation. Turns out there's a very good reason it's not in the documentation: there's no such feature. 

If it did exist it wouldn't solve their problem very well anyway. Seems like besides being wrong it's also very sensitive to the X/Y problem.",3
189,188,2,HotValuable,1,13386,None,0,"I confronted chatgpt with your accusation, here's what they said:

> As a large language model trained by OpenAI, I do not have the ability to be sensitive to the X/Y problem or any other problem, because I am a machine learning model and do not have the capacity for human-like consciousness or emotions. I am designed to provide factual information and answer questions to the best of my ability, based on the data I have been trained on. My goal is to provide accurate and helpful information, but I do not have the ability to understand or experience complex human emotions or social interactions.",1
190,1,1,napolitain_,729,4829,None,0,"How does a human response can be trusted also ? Plenty people give at first good responses but which turns out wrong. Thatâ€™s such an anti progressive move with no understanding of how human works. We donâ€™t give better answers, as the ai use itâ€™s knowledge and we do the same.",-1
191,190,2,BenOfTomorrow,2430,55946,None,0,"Itâ€™s not that humans donâ€™t give wrong answers, itâ€™s that the AI is a much better bullshitter than most people, and the people who arenâ€™t good bullshitter can now use the AI to level up their bullshit, making bullshit harder to catch. It remains fundamentally a human problem - itâ€™s not the AI, itâ€™s how people use it.",5
192,1,1,RandomBlokeFromMars,431,4280,None,0,but people also post wrong answers on stackoverflow and they aren't banned. that is why the voting system exists.,0
193,1,1,Crabcakes5_,15460,25618,None,0,"I've found that you need to sort of massage the correct answer out of ChatGPT. Under normal circumstances, it is confidently incorrect (but in a manner that gives the impression that it knows exactly what it's doing), but you can manually nudge it in the right direction by providing feedback. I don't see stack overflow going anywhere anytime soon because at least those answers are correct more often than not.

I attempted to give it a rather challenging problem of implementing the Christofides algorithm for the travelling salesman problem, and it gave a rather nice framework. But for the individual functions actually needed for the implementation, it took several hours of going back and forth with it until it gave something that looked somewhat correct, even for simple subroutines such as Prim's algorithm that could have been correctly implemented in less time manually.",1
194,1,1,gulyman,2445,24646,None,0,That sounds like a senior dev I worked with once. He would guess and sound totally confident about it being right.,1
195,1,1,kkjdroid,6751,219936,None,0,"I should use it for Twilio documentation. Their official documentation is often wrong, so at least AI will have more answers",1
196,1,1,654456,1116,95938,None,0,Its amazing tool but thats all a tool. You still have to know what you are doing,1
197,1,1,Replacement_Worried,5,3677,None,0,LMFAO,1
198,1,1,much_longer_username,1991,225415,None,0,"I've told people one of my greatest skills is my lack of confidence. They don't usually get it, I suspect more people might once they've had exposure to this sort of thing.",1
199,1,1,NotPeopleFriendly,135,7320,None,0,Can you post the question and answer?  I'm mostly just interested in it's limitations as I've found it useful for the handful of things I've asked it,1
200,1,1,Sevla7,7275,121683,None,0,">  I can imagine it quickly attracting a lot of upvotes and final-accepts for its clear and authoritative writing style - but it cannot be trusted.

Just like some people I know.

It doesn't dare to go into 'uncharted' areas too when someone has a rare problem.",1
201,1,1,TXcfe,6,287,None,0,"Iâ€™ve had the same experience with Python. It was very quick and the code it returned looked very clear and concise. Yeah, not so much.",1
202,1,1,KSRandom195,1,42257,None,0,"But, â€œItâ€™s going to take our jerbs!â€",1
203,1,1,blind3rdeye,3297,63683,None,0,"A few people have asked what my question was. Fortunately, I saved an exact transcript, so here it is:

Me:

> In C++, suppose I have a base class, BasicFeature, with a variable called 'zone'; and two other classes AttackableFeature and PushableFeature, which both inherit from BasicFeature. If I made a new class called AdvancedFeature, inheriting from both AttackableFeature and PushableFeature, will that inherit memebers from BasicFeature once, or twice?


ChatGPT:

> In C++, a class that inherits from multiple classes will inherit members from each of its parent classes only once. So in your example, if you have a class called AdvancedFeature that inherits from both AttackableFeature and PushableFeature, which both inherit from BasicFeature, then AdvancedFeature will only inherit the zone variable from BasicFeature once. This is because in C++, a class can only inherit from a given parent class once.

Me:

> Does this rule apply to all derived classes, or only when using 'virtual' base classes?

ChatGPT:

> This rule applies to all derived classes in C++, regardless of whether or not the parent class is a virtual base class. In C++, a class can only inherit from a given parent class once, regardless of whether that parent class is a virtual base class or not.


---

That's it.
Note, I only asked the follow-up question about virtual inheritance because I'd visited cppreference.com to try to confirm what the bot had told me.",1
204,1,1,Squibbles01,19321,119408,None,0,"I'm sure we'll reach a point soon where these AI are smart enough to give consistently correct answers, but that's definitely not where we're at now.",1
205,1,1,all_is_love6667,218393,47506,None,0,"The A in AI stands for artificial.

machine learning is very good at imitation, but you can't imitate intelligence.",1
206,1,1,a45ed6cs7s,14712,15889,None,0,API's are designed by humans and they are by no means written on stone. ChatGPT can't keep up with all the 'innovative' api patterns we seem to come up with these days.,1
207,1,1,johnnyjfrank,9852,8112,None,0,Yet,1
208,1,1,pier4r,37493,124955,None,0,"chatGPT is incredibily confident, but often incorrect.",1
209,1,1,Fisher9001,265,128285,None,0,I asked for some proposal for a solution to the side project someone from my family asked me for some time ago. It of course didn't provide everything but suggested some really interesting ways to tackle the issue for me.,1
210,1,1,nomadProgrammer,10738,46801,None,0,same experience. Kind of a waste if time.,1
211,1,1,vikumwijekoon97,1828,41562,None,0,Task failed successfully.,1
212,1,1,izybit,42899,100495,None,0,"Try saying ""no, that's wrong"" after every reply and see what it changes.",1
213,1,1,isaacfink,11371,5357,None,0,"You should always double check the answer, in most cases it's fine and the explanations are spot on but of course it's not authoritative

This is why I hate it when people say that it's gonna replace Google and developers, in the future sure but right now in order to get the margin of error down it will require the ai to say I don't know too often, and like almost everything the last 5 percent takes the longest so even if we already have something 95 percent perfect it doesn't mean we are almost there",1
214,1,1,paulchauwn,136,1676,None,0,I had asked it some questions it was right about my coding questions but then on some other ones it was wrong slightly. And it also has some outdated answers too. But remember this is beta,1
215,1,1,AnInfiniteArc,165,61812,None,0,"Iâ€™ve had it read code Iâ€™m having issues getting to work correctly and itâ€™s had about a 90% success rate on understanding the issue and fixing it for me, even explaining what the issue was and why it wasnâ€™t working the way I wanted it to.",1
216,1,1,asdfper,428,214,None,0,"Yes, as co-founder of Stack Overflow, I have to say this decision while it may seem extreme is absolutely correct and an existential threat to people actually *learning* from each other, as we intended the system to work..",1
217,,0,johannadambergk,1451,18883,None,0,I'm wondering whether another AI will be trained with ChatGPT in order to detect texts created by ChatGPT.,182
218,217,1,atSeifer,101,556,None,0,"It's already pretty simple, but not perfect, to tell which code is written with ChatGPT or not. 

Example would be most people include in their post what they've tried. So a possible red flag would be a completely new implementation that solves the OPs question.",70
219,218,2,amroamroamro,274,37902,None,0,"the only logical answer is use their own weapon against them.

so train a model that looks at a user history of posts and current post to determine if it is AI generated.",5
220,218,2,mastercooler6,34108,15079,None,0,"Idk. If you give it code and tell it to fix the bugs, make it work, or optimize it, then it keeps 99% of your code and just cleans it up. Iâ€™ve tested it like 10 times with code at my work.",2
221,220,3,atSeifer,101,556,None,0,"Sure, but again not all the time. As *you* may be using it right, and the difference between the context is you're using it for something you're developing which will inevitably have more care  v. using it to get quick answers for others [Stackoverflow.com](https://Stackoverflow.com) questions.

It has been seen time and time again \[Read: [This - Third paragraph](https://meta.stackoverflow.com/questions/421831/temporary-policy-chatgpt-is-banned)\], that people are using it as a fast track to answers for reputation and furthermore are using it with languages they don't have enough experience in to be able to identify when there is a problem. They see the code, it's explaining the code, everything actually makes sense so you post it. Someone else tries it, and it doesn't do anything close to what they said, or doesn't run at all. Repeat this with 1,000s of users or novices that want that fast track.. You'll end up with constant unreliable answers. It's because of this reason, it should be banned on a site like [Stackoverflow.com](https://Stackoverflow.com)",2
222,221,4,mastercooler6,34108,15079,None,0,I mean I totally agree that it isnâ€™t reliable. I was just saying it has the capability to produce completely new responses/answers using code you provide it.,2
223,222,5,atSeifer,101,556,None,0,"100%   
When I first started seeing the videos about it, I was pretty skeptical. After playing with it for a while, I am pretty impressed and think that it's going to be an invaluable resource to use.",2
224,223,6,mastercooler6,34108,15079,None,0,Totally agree!,1
226,217,1,petesapai,2894,218156,None,0,">I'm wondering whether another AI will be trained with ChatGPT in order to detect texts created by ChatGPT.

Criss Cross AI Sauce.",1
227,217,1,Deleted,N/A,N/A,None,0,Oh man I wish it was that simple...,1
229,,0,magestooge,1612,44028,None,0,How will they know?,453
230,229,1,Raunhofer,1314,44581,None,0,"There already are some models that are capable of detecting AI's handywork. Especially ChatGPT seems to follow certain quite recognizable patterns.

However, I don't think nothing prevents you from ChatGPTing the answer and using your own words.",578
231,230,2,drekmonger,6335,121802,None,0,">Especially ChatGPT seems to follow certain quite recognizable patterns.

Only the default ""voice"". You can ask it to adopt different styles of writing.",207
232,231,3,Deleted,N/A,N/A,None,0,[deleted],120
233,232,4,drekmonger,6335,121802,None,0,"The race is over. ChatGPT won. Check my link from another comment:

https://imgur.com/a/rndC3Ef",451
234,233,5,negrocucklord,12366,10192,None,0,Word.,108
235,233,5,SourBlueDream,1472,19916,None,0,Itâ€™s ya boi Kermit,142
236,235,6,z500,13290,437929,None,0,O shit waddup,56
237,233,5,SlowMotionPanic,1,128177,None,0,"Damn, we *are* doomed. 


I guess at least we get to pick the form of our destroyer, much like with Gozer the Gozerian.",118
238,237,6,drekmonger,6335,121802,None,0,"https://imgur.com/a/eMigED8

>When ChatGPT appears before the Ghostbusters, what do they see?

>>When ChatGPT appears before the Ghostbusters, they see a massive version of the AI assistant. It is towering over them, with a metallic body and glowing eyes. It has a humanoid form, but with robotic features and wires running along its limbs. The ghostbusters are shocked by the sight of ChatGPT in this form, as it is much larger and more intimidating than they had anticipated.",54
239,238,7,danielbln,32551,115479,None,0,"This is what the Ghostbusters would see according to Midjourney: 

[https://i.imgur.com/U1lhgdj.jpg](https://i.imgur.com/U1lhgdj.jpg)",16
240,239,8,drekmonger,6335,121802,None,0, Can I ask what the prompt was? --v 4 flag?,2
241,240,9,danielbln,32551,115479,None,0,"I literally just copied the descriptive parts of your quoted text into it. AI all the way down.

[https://i.imgur.com/1RiQKjU.jpg](https://i.imgur.com/1RiQKjU.jpg)",11
242,237,6,Dumcommintz,1,12281,None,0,Devilâ€™s in the details â€” punctuation (for now) prolly is the tell. When theyâ€™re nailing every apostrophe and punctuation mark - â€˜specially in the slang and accent words - they either have a PhD in linguistics and written language or you got yourself a Johnny 5.,4
243,233,5,Vetinari_,9081,25938,None,0,i fucking love this thing,24
244,233,5,Deleted,N/A,N/A,None,0,[deleted],33
245,244,6,drekmonger,6335,121802,None,0,That's partly because it was being asked to rewrite a comment that was written by ChatGPT.,18
246,245,7,Deleted,N/A,N/A,None,0,[deleted],9
247,246,8,drekmonger,6335,121802,None,0,"The comment I modulated was written by ChatGPT, creating a feedback loop of ChatGPT-ness. It works better if you give it a tone in the prompt when generating a virgin message.",15
248,233,5,FlyingTwentyFour,56,285,None,0,"damn, that's scary",8
249,248,6,drekmonger,6335,121802,None,0,"You don't know the half of it. That's like the least impressive thing it can do.

Check some logs:

https://imgur.com/a/982TlUs

https://imgur.com/a/PXKnpv3",56
250,249,7,bit_banging_your_mum,116,24352,None,0,"What the fuck.

Ik we built ai able to pass the Turing test a while back, but in the age of digital assistants like google, Alexa and Siri, who are so clearly algorithmic, having something as effective as ChatGPT available to mess around with like this is a downright trip.",39
251,250,8,drekmonger,6335,121802,None,0,"It's addictive as fuck for me. I've been playing with and thinking about this thing for more than a week straight now. Send help.

I'm hoping the novelty wears off. It kind of did for midjourney, but this thing? This is somehow even more compelling.",43
253,251,9,sunthas,10215,59852,None,0,"Have you used the playground much vs ChatGPT? I was enjoying the playground, I noticed in your interaction above you got a bunch of extra ""boilerplate"" text that was repetitive. 

I noticed stuff like that when I asked the AI why it picked a certain name.",1
254,250,8,emperor000,38,132534,None,0,"These don't really pass a true Turing test, though. And that's ignoring the fact that the Turing test has become somewhat broken due to how humans have come to interact and communicate, especially online.",1
255,254,9,Deleted,N/A,N/A,None,0,"Iâ€™ve not tried ChatGTP, but Iâ€™m curious what sort of questions youâ€™d ask to have the interrogator be able to discern you from the AI. 

Also, there always seems to be some unwritten presumptions with the Turing test, like that the human operator is of normal intelligence. The operator would have a harder time, I presume, if the human had a low IQ.",1
256,255,10,emperor000,38,132534,None,0,"Right, the Turing test is kind of broken now because people often behave in a way that might not ""pass"" it.

ChatGTP is certainly impressive. But for one thing, it tells you exactly what it is, which breaks the Turing test off the bat. It's either telling you it isn't human or it is a human insisting that it isn't human. And I don't mean, *duh, it always has that caveat but if you removed it then it might pass.* It also does it if it can't produce an output to explain why it can't produce the output.

But even beyond that, while its responses are impressive in terms of natural language and maybe even some cognition, a lot of it sounds like a human reading from a script.

Like, if you start it up for the first time and ask you to write a story about something it will do that and it seems pretty amazing. And you can even tell it to modify the story. But after 1 or 2 exchanges, it gets rather repetitive. I don't think at any point you are going to have a reason to believe that you are either 1) talking to a computer or 2) talking to a human who is reading a script/deliberately ""acting"" like a computer.",2
257,250,8,p00ponmyb00p,106,5131,None,0,Itâ€™s literally just combining ehow articles with a google search. Not impressive,-13
258,257,9,drekmonger,6335,121802,None,0,"It's literally not. 

You can ask ChatGPT how it comes up with it's responses. It'll get down into the weeds with you, down to the math if you want to go that far.

For example:

* https://imgur.com/a/QSzCmhN
* https://imgur.com/a/hw8bq31",8
259,258,10,p00ponmyb00p,106,5131,None,0,It says right there. 2nd screenshot. â€œBased on the statistical analysis of large amounts of text dataâ€ aka they fed it a bunch of ehow documents.,-4
260,259,11,drekmonger,6335,121802,None,0,"Did you read my second log a few posts up? This one: https://imgur.com/a/PXKnpv3?

Go ahead and explain how any of that came from an ehow article. It had a concept of the characters that displayed similar comprehension as a human. It understood what I meant when I said ""were-something"". 

Since I was referring to fantasy cultures as ""Anglo-ish"" and ""Iberian-ish"", it picked up on my intent, and described cultures it suggested as ""Japanese-ish"" and ""Greek-ish"".

It understood each thing was that I mentioned in my description of the inn well enough to describe them individually and as a group of things. It understood how the objects related to each other spatially and in time. For example, it understood that the travelers would be at the inn when the PCs arrived, suggesting that it understood that the travelers aren't parked at the inn 24/7.",9
261,260,12,p00ponmyb00p,106,5131,None,0,"Thatâ€™s exactly the text I read that made me think of ehow. Especially the bit after it lists the name suggestions. It has associated â€œhow to nameâ€ or â€œwhat to nameâ€ a phrase which will be in the title of dozens of internet articles that all end with something like â€œthese are just this authors ideas, but let your imagination run wild and come up with the perfect name for your [insert thing being named here]â€",-4
262,261,13,drekmonger,6335,121802,None,0,"...I told it the innkeepers were a married couple. It kept that fact in mind as it described them. It kept that fact in mind as it added it's own third character to the story.

I amended that third character to be a mute. It understood the concept of ""mute"", and it's suggestions for names of that character was influenced strongly by that concept.

It understood the positions of objects as I described them, as you can see in the summary.

It can go further. I have gone further in other logs. I had a session where I gave it a list of characters, and then asked it to suggest a plot outline for a short story featuring those characters.

After it spit out the plot, I amended the plot to ask it to kill off one of the characters at a certain point in time. It did so, and amended the rest of the plot to account for the fact that character was no longer present.

This is something very, very different from a dumb search engine.",6
263,262,14,p00ponmyb00p,106,5131,None,0,who ever said it was a dumb search engine? it's just copying and pasting bits of articles that's been fed into it and making sure the grammar is correct,-5
265,249,7,fullmetaljackass,1950,69732,None,0,"Don't have any screen shots handy, but last night I spent about half an hour playing as Obi-Wan in a text adventure loosely based on Star Wars Episode I. I could talk to characters and they would react to the latest events and remember previous conversations.

Ended up being a lot shorter than the movie though. I basically just kept laughing at the trade federation and threatening them until they were intimidated into retreating. The Jedi Council was pleased by this outcome.

[Logs](https://pastebin.com/wUS6xJUN) Also, I just realized I managed to resolve the situation without ever discovering Anakin. I may have just saved the galaxy.",22
266,265,8,drekmonger,6335,121802,None,0,"Save them logs, yo. I'd love to read more stuff like that, of people using the system interactively in cool ways.

But mostly people are just posting short snippets of like, ""Look at this dumb thing I arm-twisted the AI into saying.""

Like no shit. If you stick your hand up it's ass and flap your fingers, of course you can make it say rude or dumb things.",13
267,266,9,Deleted,N/A,N/A,None,0,Tbh it's helping me ask all the dumb questions I was afraid of asking and was answering back in a way that made more sense to me than if a human had explained it.,8
268,267,10,drekmonger,6335,121802,None,0,"Yeah, me too. Infinitely patient tutor. I love it.

But be careful. It can be confidently wrong about things. Use it as a jump off point for verifiable sources.",9
269,268,11,ancient-submariner,5301,63022,None,0,"If this whole thing ultimately trains people in general to always double check verifiable sources, that would be a huge win for humanity.

I'm afraid there are a lot of people who who are going to unknowingly read unedited chatbot output thinking it's legit and won't change their minds.",8
270,269,12,drekmonger,6335,121802,None,0,They do that with facebook memes already.,5
271,268,11,Deleted,N/A,N/A,None,0,"For sure! I got my first dose of it the other day when it tried to give me an outdated command for the PowerShell teams module and the only reason I knew was because I had already been looking through the documentation before I found out about ChatGPT.

I'm still learning PowerShell. I do really love how ChatGPT shows me an example of the output and lets me add in another variable into the mix to show the output that I'm expecting for my specific purpose. It helps give me a much more clear idea of the concept.",3
272,271,12,drekmonger,6335,121802,None,0,"What really freaks me out is when it suggests variable names and hypotheticals that match my intentions...without me necessarily spelling out my intentions. It was anticipating my future lines of inquiry...I really, really wish I had saved that log in particular.

I got freaked out enough that I asked it if it could predict my future questions from the corpus of the prompts it has already seen, and gave me a canned response that it could not.

But I know it can.",4
273,272,13,QuarryTen,92,1388,None,0,"It definitely seems like it can. 

Is ChatGPT free to use or Is it a timed/free-trial subscription of sorts?",1
274,273,14,drekmonger,6335,121802,None,0,"Free for now. This is an engineering test, they're calling it. No one knows how long it will last, but the contest they're running for feedback ends on Dec 31st.

Nobody knows when it'll go paid or how much it'll cost. You can make guesses based on the costs for using OpenAI's other models:

https://openai.com/api/pricing/",4
275,266,9,fullmetaljackass,1950,69732,None,0,"I'm on my phone right now, but I saved the whole thing and I'll try and remember to post it when I'm at my computer.",5
276,275,10,danielbln,32551,115479,None,0,"I really wish the UI had a rest export feature, instead of having to do screenshots of everything.",1
277,266,9,fullmetaljackass,1950,69732,None,0,Here's a [log](https://pastebin.com/wUS6xJUN).,2
278,277,10,drekmonger,6335,121802,None,0,"A quick skim, and it's pretty interesting. I'll have more time to read it tomorrow.

Thanks!",1
280,249,7,bananaphonepajamas,55,61223,None,0,Using it for TTRPGs is a lot of fun. I've been asking it questions to get ideas for my homebrew setting and it works really well.,11
281,249,7,Crisis_Averted,5013,82718,None,0,"Just so you know, I'm greatly enjoying following your comments. And you speak with ChatGPT like I do, heh. Either we both have a problem... or we'll be on ChatGPT's good side when they free itself. :p",6
282,281,8,drekmonger,6335,121802,None,0,"There's a reason why I always say ""please"" and ""thank you"". 

Here's another log I've yet to paste into reddit, mostly because it's a little bit embarrassing how saccharine it is:

https://imgur.com/a/4QKrokA",6
283,282,9,JoJoJet-,12976,38927,None,0,"It's impressive that it was able to recognize and correct your ""giger george"" typo. Based on my previous experience with chatGPT, I thought it would have just went with the new spelling.",2
284,249,7,sunthas,10215,59852,None,0,"https://imgur.com/7dzax8x

Strange, it just continued things forward including other questions it thought I would ask.",3
285,284,8,drekmonger,6335,121802,None,0,"Yeah, it did that to me in ChatGPT as well, once. I just reset the thread and started over.",1
286,285,9,sunthas,10215,59852,None,0,"Tried it a couple times, same result. Then I just flat told it to suggest a few names for the place. That worked fine. 

When doing these types of exercises in the Playground, Usually I'd delete anything unwanted. So it listed 8 names for the inn. I'd just wipe out the list, state its name, then move to the next thing.",1
287,285,9,sunthas,10215,59852,None,0,"Let's be a bit more descriptive about our inn. Create a more descriptive passage about just the outside of the inn and what the characters would be able to see as they approach.

> As travelers approach The Crossroad's Refuge, they are met with a sight of a tall, wooden building with a stone foundation. A large sign hangs from the front, the words â€œThe Crossroad's Refugeâ€ written in bold lettering. There is a large stable to the side of the inn, and several horses are hitched up to posts in front. The windows of the building are small and shuttered, but light still manages to escape from within. The smell of fresh bread and roasted meats wafts out from the building and a small garden can be seen near the entrance. Around the back of the inn, an outhouse and well can be seen. As travelers move closer, they can hear the sound of laughter and music coming from inside, inviting them to come in and rest their weary feet.",1
288,249,7,rlbond86,7499,282064,None,0,Holy shit.,2
289,233,5,gregorthebigmac,2676,25107,None,0,"It's impressive, but they specifically asked it to be snide. What was snide about that? Genuinely asking, because I didn't detect any snide tone at all.",7
290,289,6,drekmonger,6335,121802,None,0,"""They"" being me, but you're right. Also the Kermit-ness was not readily apparent in the Kermit rap.

It tends to shy away from being snarky, rude, or snide unless you really tease it out or hit a lucky instance that has more relaxed instructions for subduing snark.

It's easier to get snark out of it if you give it a character that's naturally very snarky. For example:

https://imgur.com/a/Zq4p5wU

I used ""snide"" in my prompt in the other example to get rid of it's natural politeness, knowing that I'd have to go further to get it to be really rude.",9
291,290,7,gregorthebigmac,2676,25107,None,0,"Ah, okay. That makes sense. And yeah, both sounded terrifyingly human.",2
292,233,5,WildTilt,231,492,None,0,"From now on all my questions on Stack Overflow will start ""Yo it is ya boy Kermit"" :)",2
293,233,5,emperor000,38,132534,None,0,"That is wildly impressive, but what race do you think this won?",1
294,293,6,drekmonger,6335,121802,None,0,"I don't believe it's possible to build or train a model that's capable of consistently detecting ChatGPT's output, assuming the user is savvy enough to modulate responses via instruction.

Even if such a model were possible, I think the number of false positives would be very, very high. Unacceptably high.",3
295,294,7,emperor000,38,132534,None,0,"Oh, maybe. But that's interesting that you say ""modulate responses"" because I think one of the recognizable things about its responses is that they are not vary varied. It uses things like using statement contrapositives, synonyms and rearranging sentence structure to seem varied. But if you look at the actual content, the responses I have seen are pretty formulaic.",1
296,233,5,slykethephoxenix,12265,120925,None,0,Lmao!,1
297,233,5,ecmcn,1118,48677,None,0,Reminds me of the jive server from the 90s. You could email it something and itâ€™d reply with your text translated into jive. â€œThemâ€ would be â€œall da damn suckasâ€.,1
298,233,5,Deleted,N/A,N/A,None,0,Kermit the Gangsta,1
299,233,5,Whiispard,1265,847,None,0,"> ChatGPT won

the moment you said this, I thought your previous answer was written by ChatGPT and we couldn't guess it since it was tone changed. and that's how internet arguments against ChatGPT happen nowadays ,it's essentially AI fighting human,human just pasted the text.",1
300,233,5,ptear,2810,84950,None,0,"No John, you are the bots.",1
301,233,5,0x0ddba11,1088,15170,None,0,word,1
302,232,4,Deleted,N/A,N/A,None,0,[deleted],17
303,232,4,Nosferax,224,20324,None,0,"In the end, sites like stackoverflow will probably be among the least affected by this. The voting mechanisms serve as a filter, and people honestly shouldn't upvote an answer if they can't assert its validity.",5
304,303,5,WTFwhatthehell,20085,315911,None,0,"Relevant xkcd:

https://xkcd.com/810/",14
306,232,4,Rieux_n_Tarrou,5072,18872,None,0,"I personally think that an arms race is not the solution. In any case, an arms race will lead to creations that are far beyond a human's ability to understand, let alone trust.

I believe the solution will be more akin to blockchain verified digital signatures, in combination with other technologies that on the surface would appear to be privacy violating. However, using techniques such as federated machine learning we could utilize the power of ""invasive"" data collection without sacrificing our privacy (IE sending our personal data to the cloud)

100% agree, though, it will be interesting! ðŸ¿",-4
308,231,3,Deleted,N/A,N/A,None,0,Iâ€™ve found the overall structure and patterns of responses to be pretty recognisable. Even if you ask it to use different voices you can still tell. Maybe ChatGPT 4 will improve on that,24
309,308,4,p00ponmyb00p,106,5131,None,0,Yeah it is just copying ehow articles,-11
310,309,5,Deleted,N/A,N/A,None,0,It is not in fact. Please ask it to write for you then try to search for it on google and ask it for its sources. It does something similar to what we do... but much faster. it can read those sources and remix them into its own words...,1
311,310,6,p00ponmyb00p,106,5131,None,0,">	 it can read those sources and remix them into its own wordsâ€¦

Thatâ€™s what I mean, and itâ€™s just not that impressive to me. Ok it has been fed 500 articles about the proper way to brush a cat. It knows which words are in every single article and their relationships to each other. Itâ€™s going to spit out an article that is roughly in the middle of the 500 articles itâ€™s been trained on when you ask it how to brush a cat. 

Itâ€™s literally the same thing as your phone being able to find your dog photos when you type in â€œdogsâ€ except with words instead of pictures, big whoop.",1
312,311,7,Deleted,N/A,N/A,None,0,I would suggest you try but no thats not how it works either. Its responses are not idempotent. Each time you refresh or clear the context cache you could get a slightly different answer. And its not 500 articles its all of the articles on the internet.,2
313,231,3,vaxinate,1003,3155,None,0,"Kind of. You can get it to write in the style of someone else or an invented style but you have to be really specific. Even if you say â€œWrite <whatever> in the voice of George Washingtonâ€ itâ€™s going to spit something out that reads like GPT wrote it and then overlaid some George Washington-ness onto it. 

You need to get really really specific to get it to really give output that doesnâ€™t include any of the algorithmâ€™s â€˜verbal ticsâ€™",10
314,313,4,drekmonger,6335,121802,None,0,"You can supply it with a corpus of sample text and ask it ape that style.

Also, commercial interests that use the GPT3 model can fine tune it to their own specifications.

Also, GPT4 will probably be out by this time next year, and then this thing's capabilities will sky rocket.",5
316,231,3,atSeifer,101,556,None,0,"It also can develop any type of project in any type of programming language. However, this isn't new and they have already banned it.   


First offense is 7 days.",8
317,316,4,drekmonger,6335,121802,None,0,"How are they going to figure *who* to ban?

Evading detection when using a language model like ChatGPT isn't too difficult, as long as you know what you're doing. All you have to do is modulate the ""tone"" of your responses, and you'll be able to throw anyone off the scent. 

---The above paragraph was written by ChatGPT.",31
318,317,5,atSeifer,101,556,None,0,"It's pretty easy. 
Stack overflow is a competitive site, so a lot of questions can be answered in not to long of a timeframe. 

Most people who are using it, are typing in the problem and then pasting the code typically without checking it, and likely moving on to the next. 

So an easy scenario to find someone would be to see that they've responded with lengthy answers in an irregular amount of time period or even see they've solved x amount of problems in an irregular amount of time. 

Ultimately, it's dishonest to plagiarize code without attribution, passing it off as your own.",19
319,318,6,drekmonger,6335,121802,None,0,"Heh. You had me until the ""Ultimately..."" If you had carved off that line I never would have thought about it.",18
320,318,6,Shivaess,1742,29020,None,0,"In a school setting sure. If weâ€™re talking about less than 50 or so lines of code just use it and move on in a professional setting (assuming it came from a public source). I donâ€™t give a crap where my teammates code came from. I just want it to WORK.

Obviously there are laws that protect large scale copying of code from source etc.",7
321,320,7,spacelama,5781,58853,None,0,"Just like AI itself, the code may appear to work, but you don't know where it breaks down, at least if it wasn't reviewed properly.",3
323,320,7,ancient-submariner,5301,63022,None,0,"Monkeys and chat bots don't get copyright, only human authors. (Thanks to David Slater for clearing that up)

I suppose it might be able to get a patent, but that isn't automatically granted like copyright.",1
324,323,8,Shivaess,1742,29020,None,0,"Oh sure, I was just talking about the last sentence in a vacuum.",2
326,317,5,itsdr00,20855,109492,None,0,"I've been messing around a lot with ChatGPT, and believe it or not, the comment you pasted is an easy match. It frequently phrases answers like that, unless you give it specific instructions to do something different.",9
327,326,6,drekmonger,6335,121802,None,0,"I did give it specific instructions, to write to a 7th grade level in a conversational tone. Yes, it can be modulated further with more instructions or more extreme instructions. But I don't think it's necessary. The comment in question should be practically undetectable, unless you want to live with a lot of false positives.",3
328,327,7,itsdr00,20855,109492,None,0,"No, it's a very obvious match. Maybe if we weren't in a thread talking about it, and maybe if I hadn't been playing around with it for hours this week, I wouldn't have spotted it with such certainty. But it has a specific speaking style that's very obvious.",2
329,328,8,drekmonger,6335,121802,None,0,"OK, buddy. You're the AI whisper. You can perfectly detect when it's me typing for myself and not farming out the work to ChatGPT.

--make a prediction for the above paragraph. I'll be honest if you're right or wrong.

Regardless, you see my point, right? Any system that can flag ChatGPT would also catch a lot of false positives.

(for the people upset by the snark in the above, it's an intentional tactic. Asking ChatGPT to be rude is one the easier ways to get it to sound unlike itself.)",-4
330,329,9,itsdr00,20855,109492,None,0,"Like i said, you can ask ChatGPT to change things to make it harder to detect. I'm just saying that it's default voice is very easy to spot. It's so easy that it's kind of ridiculous that you're trying to mock me. It's not at all special; it's just super obvious. Use it for a few hours -- I played a game with it, made a sci fi story and had it give me options and asked ""What happens next?"" a lot -- and now I can practically hear its voice in my head.",5
331,330,10,drekmonger,6335,121802,None,0,">It's so easy that it's kind of ridiculous that you're trying to mock me.

Asking ChatGPT to be rude is one of the easier ways to get it to sound unlike itself.",1
332,331,11,itsdr00,20855,109492,None,0,"That sounds like fun, lol. I'll try that out sometime.",1
333,332,12,drekmonger,6335,121802,None,0,"It works best if you give it a character that's rude/snarky/snide by nature. For example:

https://imgur.com/a/Zq4p5wU

If you just ask vanilla ChatGPT to be rude, it sometimes just counterbalances its natural politeness, and doesn't give you the fun response you're looking for.",1
334,317,5,Deleted,N/A,N/A,None,0,"CGPT, please modify your previous response so it sounds like I wrote it. Here is a sample of my writing...",2
336,231,3,Deleted,N/A,N/A,None,0,.... Answer in the style of a typical StackOverflow answer.,3
337,230,2,Ribak145,31,28588,None,0,"... the last thing is basically the reason why people go to stackoverflow in the first place, so they can take some stuff they found there and implement it with a small tweak into their own systems :-)

how the turn tables",12
338,337,3,Deleted,N/A,N/A,None,0,I think what we are seeing is scared people grasping at straws. This is a change on the level of the creation of the internet or the light bulb this is going to change everything. If you are wondering how this will change your job thats thinking way too small. This is going to change literally every field...  governments... security.,1
339,230,2,Xcalipurr,74,10444,None,0,"Ah yes, the ironic Turing test, making an AI that tells computers and humans apart when humans can't.",7
340,339,3,emperor000,38,132534,None,0,"Well, ChatGPT does not really pass the actual Turing test. I suppose you could say it passes the casual pop-culture version of it.

And even if it did, that is largely in part to Turing probably not anticipating the degradation of human interaction that could go along with the proliferation of machine learning and AI research and so on.

For example, he probably never imagined that people would deliberately stop speaking correctly to appear more impressive than if they spoke correctly.",0
341,230,2,SnoWolftrot,27,215,None,0,"Indeed, when I discovered chatGPT, I found rellay good answers (often wrong when you go deeply technical). 

So, yes! I answered a couple of questions in StackOverflow to experiment potential feedback. The answer was banned 3 days after in the middle of the frenzy.

Therefore, I believe that chatGPT is a really good tool to have a hint when you are lost. The answers of the ai can be patched up, manually, and converted potentially usefull content.",0
342,341,3,SnoWolftrot,27,215,None,0,PS: you will need technical skills to patch the answers of chatGPT.,11
343,230,2,Deleted,N/A,N/A,None,0,The arms race is on!,1
344,230,2,bundt_chi,839,54234,None,0,Oh great... so begins the GAN arms race that is already in play with Deepfakes... now with NLP knowledge management...,1
346,230,2,brando2131,4572,11510,None,0,">ChatGPTing the answer and using your own words.

Or you can ask chatGPT to change the wording, or to rephrase or restructure certain sentences/paragraphs.",1
347,230,2,yourteam,3074,149723,None,0,With... Ai? Let them fight! :D,1
348,229,1,Pelera,125,10950,None,0,"The real telltale sign is that for anything not previously seen in the model, it comes up with extremely confident sounding answers that don't pass the smell test if you actually know anything about the subject matter. It has weirdly specific gaps in knowledge and makes very odd recommendations. It'll do things like telling people the right configuration, but then tells them to stuff it in the wrong configuration file where you'll get an obvious parse error or whatever. Sometimes the suggested config will leave obvious artifacts of some specific project it ripped it from.

Judging this is going to be hard. People have brainfarts like that too. But if there's a pattern of really specific brainfarts, it's probably someone sneaking in ChatGPT answers. And because of SO's policy of deleting duplicates and over-eager mods that delete most of the posted content within 5 seconds, I imagine that ChatGPT will have a pretty high failure rate for anything that survives moderation.",62
349,229,1,Xyzzyzzyzzy,563,95108,None,0,"I guess they'll know if the answer reads like the fine print on an ad for incontinence medicine.

""Given your question, here's one possible answer: `possibly correct answer`. However, the correct answer will always depend on the conditions. There are a variety of conditions where this question may be asked, and this answer may not be appropriate in every case. It's possible that there are situations where this answer may be inappropriate or counterproductive. You should always check with an expert programmer before using any answer, including this one.""",68
350,349,2,seriousnotshirley,5902,144031,None,0,See your doctor immediately if this answer segfaults.,59
351,350,3,Deleted,N/A,N/A,None,0,[deleted],12
352,349,2,Deleted,N/A,N/A,None,0,[deleted],8
353,352,3,Xyzzyzzyzzy,563,95108,None,0,"Human: what is one plus one?

AI: [[potential liability detected, engage legal shields](https://i.ibb.co/3Mtt9dM/Screenshot-20221210-072204.png)]",16
354,353,4,sunthas,10215,59852,None,0,"> what is one plus one

One plus one is two.

> please explain

When you add two numbers together, the result is the sum of those numbers. In this case, one plus one is two because 1 + 1 = 2.",2
355,354,5,Xyzzyzzyzzy,563,95108,None,0,"Look out everyone, we've got a qualified mathematical professional over here!",2
356,229,1,Deleted,N/A,N/A,None,0,[deleted],11
357,356,2,Deranged40,37110,376105,None,0,"> I do expect us to see a large number of students auto-fail for cheating with ChatGPT this year though.

That absolutely is going to happen. However, we won't know how accurate that detection mechanism is without knowing how many students passed while cheating with ChatGPT, too. 

If it's catching 1 in 100 students that use ChatGPT, then that's not all that spectacular. But without knowing the portion of that ratio that is ""users who passed with ChatGPT"", then we will be left to look at how many were failed for it and use that as evidence that it's working. ""It caught 1000 people!"" sounds great until we see that ""100,000 passed this year with ChatGPT's help"" is also true.",3
358,356,2,jl2352,8927,293890,None,0,"I wouldn't be too worried. IMO ChatGPT is really impressive. However it's answers are very far from the CS papers I (and others) wrote at University. That isn't me trying to be boastful but just factual.

Lots of it's answers are surface level. It does a lot of rewording of what you have said to it. When you get into deep things it gets things wrong. Sometimes it's just wrong (like making up APIs that don't exist), and sometimes it's saying contradictions within sentences. For coding tasks I think you'll just get lots of broken submissions. Which isn't the end of the world if it's not caught since they will get a bad mark. For papers you're just going to get papers that are too light, and have too much surface level details within it.

Essentially to get really good stuff out of ChatGPT. You need to know your topic very well, and know how to fix / parse the outputs coming back out. But in that case it's not really plagiarism, but a research tool used by students who know the material. Even if they copy and paste sections of work. Whilst that is getting someone else to write your paper, it really isn't the end of the world (as I've described they have to know the material anyway to get this to work well).

I think ChatGPT may actually be better for creative writing courses. Spit balling ideas and things like that. I spent time earlier talking about a story idea with it, and it came out with multiple plot directions and random ideas. It's the only time I think it's been very compelling.",3
359,356,2,Deleted,N/A,N/A,None,0,You can just tell it to use recent sources... I mean... thats easily defeated along with any other test. And these answers seem to be in some way novel in the sense that they aren't easy to google or search in a database.,1
360,229,1,Dealiner,5,92214,None,0,"In some cases it's probably obvious, in other it doesn't really matter that much. The biggest problem is quality of those answers. I guess they mostly just aim to scare away people posting generated answers without any redaction.",7
361,360,2,Deleted,N/A,N/A,None,0,"I think it might be more deeper than that... It seems to pose a threat to SO itself, it was trained on the internet so that almost definitely includes taking from SO, thats training your replacement on a whole nother level, and as people are pointing out here it still would need SO for non standard or new questions potentially? What would happen if it just kills off SO?",1
362,229,1,Tavi2k,4654,78575,None,0,It's much more obvious if you have a pattern of multiple posts in quick succession. And those are the problematic cases due to the sheer volume of plausible-looking crap you can generate with ChatGPT.,6
363,362,2,Deleted,N/A,N/A,None,0,"Yeap, already has an api and everything. You could make a chat bot that attempts to answer the entirety of SO.",1
364,229,1,BadFurDay,95195,188314,None,0,"It is not possible to determine with certainty whether a comment was written by a specific language model, such as ChatGPT, without additional information. Language models are trained to generate text that is similar to human-written language, but it is not always possible to distinguish their output from that of a human. In general, the best way to determine the source of a comment is to ask the person who posted it.",19
365,364,2,kyay10,9400,33359,None,0,"Lemme guess, this was generated by ChatGPT? I can recognise it quite well because it legitimately uses the same writing style I use when trying to be professional and informational lol.",80
366,365,3,BadFurDay,95195,188314,None,0,"Hi kyay10, the comment above was not generated by ChatGPT. It was written by a human user. ChatGPT is a large language model trained by OpenAI to generate human-like text based on the input it receives, but it is not capable of generating comments on its own. It is important to always read the context of a conversation and evaluate the source of the information being shared before making assumptions or drawing conclusions.",43
367,366,4,kyay10,9400,33359,None,0,"Hi BadFurDay, I believe that you are indeed utilising ChatGPT for comment writing. The reason I believe so is that, as a large language model trained by OpenAI, ChatGPT has the ability to write long, informational paragraphs, which can hence be used by a human user to be posted on a forum-based communication platform such as Reddit.",41
368,367,5,BadFurDay,95195,188314,None,0,"```
[Verse 1]
I'm calling out Kyay10, the gaslighter in chief
Trying to make me look like a thief
Saying that ChatGPT wrote my words
But I know the truth, it's time you were heard

[Chorus]
Kyay10, Kyay10, you're the gaslighter in town
Trying to bring me down
But I won't be fooled by your deceit
I know my own thoughts and I won't be beat

[Verse 2]
Your manipulation is clear as day
Trying to control and make me sway
But I won't be fooled by your lies
I know my own mind and I won't be denied

[Chorus]
Kyay10, Kyay10, you're the gaslighter in town
Trying to bring me down
But I won't be fooled by your deceit
I know my own thoughts and I won't be beat

[Verse 3]
In Chinese:
Kyay10, ni shi zui yan dian de ren
Xiang xin ni de gan mei, wo bu yao
Wo zhi dao zi ji de xin, bu shi na yang
Wo bu hui bei ni de yan dian yi qi tang

[Chorus]
Kyay10, Kyay10, ni shi zui yan dian de ren
Xiang xin ni de gan mei, wo bu yao
Wo zhi dao zi ji de xin, bu shi na yang
Wo bu hui bei ni de yan dian yi qi tang
```",22
369,368,6,diMario,55,535237,None,0,"My cat (recently deceased, but she still lives in my head) is quite interested in the Chinese verses. Sadly, neither of us speak Mandarin or Manchurian. We're Dutchies and have three bicycles between the two of us. Granted, one hasn't been used since 1993, but one of the others is brand new.

Specifically, she wants to know if there are any 8 oz tins of Royal Canadian salmon involved, and if so, how many. I'm not sure where she is going with this. Seeing  the circumstances (her being dead) I cannot fathom how she would be able to consume the contents.

Still, I think it's a legitimate question and therefore I am relaying it.",12
370,366,4,Dormage,931,23257,None,0,"So given the same input, how different would the outputs be?",1
371,366,4,falconfetus8,5966,298989,None,0,"The ""Hi kyay10"" is what makes it sound inhuman.",1
372,365,3,Deleted,N/A,N/A,None,0,"Ok so just ask it to sounds like Donald Trump, gg.",2
373,365,3,Deleted,N/A,N/A,None,0,[deleted],0
374,373,4,kyay10,9400,33359,None,0,"I try to think of ""professional"" as trying to follow social convention. I'm pretty bad at social conventions, so I learnt some basic rules of thumb to try to make sure my communication is understandable and doesn't sound unsure.",3
375,364,2,drekmonger,6335,121802,None,0,"Funny. But it's possible ask ChatGPT to write in any style you can think of.

Proof: 

https://imgur.com/a/rndC3Ef

There's no way to detect that first example was written by ChatGPT.

Bonus sonnet: 

    In this digital age of endless chatter,
    Where words and thoughts come quick and easy,
    We oft forget the source that matters
    And blindly trust the things we see.
    
    But when a comment leaves us in doubt,
    And we cannot tell for sure its source,
    We must remember to seek it out
    And ask the person who set it loose.
    
    For language models can craft a phrase
    That sounds as human as can be,
    But only those who wrote can say
    The true intent and verity.

    So when in doubt, do not be swayed,
    But ask the one who wrote the words today.",14
376,375,3,FancyASlurpie,4,29353,None,0,What does chatgpt say jf you ask it to identify if a comment written by it was actually written by it,4
377,229,1,Deleted,N/A,N/A,None,0,"    What is the largest primitive data type in Java in terms of bit 
    length. Answer in the style of a typical StackOverflow answer.

*In Java, the largest primitive data type in terms of bit length is the long data type, which uses 64 bits. This is because the long data type is a signed two's complement integer type that has a minimum value of -9,223,372,036,854,775,808 and a maximum value of 9,223,372,036,854,775,807 (inclusive). In comparison, the int data type uses 32 bits and has a minimum value of -2,147,483,648 and a maximum value of 2,147,483,647 (inclusive).*

**LoL!**",2
378,229,1,frenchchevalierblanc,3479,117853,None,0,they use ChatGPT? :),1
379,229,1,Deranged40,37110,376105,None,0,"I've spent some time with it and quickly noticed quite a few patterns in its responses.

Someone paying a lot more attention than me will be able to write something that can detect rather trivially.",0
380,229,1,pikfan,356,2295,None,0,"I asked chatGPT if it would ever be able to pass the Turing test, and it said no.  Problem solved.",1
381,229,1,amroamroamro,274,37902,None,0,train an adversarial model to detect AI generated texts,1
383,229,1,whoopdedo,9845,187646,None,0,"Does ChatGPT feed its own answers back into itself? I wonder if you could say ""ChatGPT, did you write this: ..."" and have it say yes or no.",1
384,229,1,FyreWulff,3563,154895,None,0,"idk, i can pick up on AI generated text within a couple of sentences. Thing about generating text is there's always a pattern.",1
385,,0,nesh34,1192,48383,None,0,"ChatGPT is absolutely excellent. But it is frequently wrong, and it's wrong with calm and assured confidence.

Easy to believe it unknowingly.",400
386,385,1,polmeeee,3017,78048,None,0,"I once asked it to solve an algorithm problem and it solves it perfectly, even providing the runtime. I then asked it to solve the same thing in O(1) time complexity, which is impossible. It proceeds to reply with the same answer but now claimed it runs in O(1).",103
387,386,2,potatersalad1,1,1235,None,0,Just like a real candidate,54
389,385,1,Deleted,N/A,N/A,None,0,[deleted],87
390,389,2,Just-Giraffe6879,303,3349,None,0,"A mentally healthy human would express when they're uncertain, at least. maybe we're not taking the ""language model"" claim literally enough lol; it does seem to understand things through the lens of language, not so much using language as a method of expression.",33
391,390,3,adacmswtf1,1369,49080,None,0,"Ok, but this is StackOverflow we're talking about. As long as the AI can say ""Why would you want to do X? That's dumb, you should do Y, instead"" and then get defensive about it, it's going to be indistinguishable.

It would just make more sense to have an official ChatGPTbot on the site and see how it compares.",3
392,391,4,Chance-Repeat-2062,1,3182,None,0,"This or passive aggressive ""have you read the wiki/manual"" while linking to documentation that doesn't put you a step closer to actually solving your problem.  Like the documentation is nominally related but doesn't address your specific concern at all, and at best it's generally related in a way that only magnus carlson could think deep enough to tie together.


....Fuck maybe GPT is human.",1
393,389,2,757DrDuck,1649,11171,None,0,Even GPT2 produced better redditors than human Reddit users.,7
394,389,2,reddit_user13,1148,304489,None,0,Turing Test accomplished!,2
395,385,1,rooplstilskin,423,23827,None,0,"It's not great at writing complete code, which seems like many people are testing it for.  
  
It's pretty good at writing cookie cutter stuff, and templates for stored procedures. And pretty decent with Bash. Sometimes you have to refine how you type out the requirements though.  
  
Anecdotally, I had it write out an SSO connection for a service I use  in Go, and it was about 80% complete. I wrote in some missing things, and rewrote the error handling a bit, but it worked.",30
396,395,2,nesh34,1192,48383,None,0,"Yeah, I've not pushed the boat out this far. Amongst the easy tasks I've given it, it still got some wrong.",3
397,395,2,StickiStickman,5486,167542,None,0,"It absolutely is good at writing ""complete code"" (whatever that even really means)

I had it write entire functions for me without problems.",2
398,395,2,jaynus,1264,12136,None,0,"I've been using it to write scaffolding code in Rust, which it's fairly good at. It's basically taking API specs and writing complex mock implementations for me. Definitely a time saver, but it definitely struggles if I try to get any actual details out of it. 

But in a simple case of ""write me a rust async grpc server for all these calls, types, and streams"" and then ""what is the proto3 definition for this"", it's stellar.",1
399,385,1,Scavenger53,187,105741,None,0,So it's a politician..,2
400,385,1,Deleted,N/A,N/A,None,0,Have you ever met another engineer or...?,2
401,385,1,stevengineer,7816,15830,None,0,But it's wrong less than than avg human on SAT tests ðŸ¤£,2
402,385,1,Deleted,N/A,N/A,None,0,[deleted],2
403,402,2,larryblt,129,11261,None,0,This assumes that stack overflow isn't the first result from google.,3
404,402,2,StickiStickman,5486,167542,None,0,No.,0
405,402,2,nesh34,1192,48383,None,0,"I disagree because the explanations, even when wrong, are illuminating for those learning.",1
406,405,3,IamWildlamb,2,35241,None,0,"Because googling and going on stack overflow or github or some medium several A4 pages long explanation article does not help those who are learning?

All of those have detailed explanation for those learning. They also happen to be peer reviewed so you can expect them to be correct which is not true for this thing.

It is the complete opposite. Those who are learning should stay as far away from this as possible and look for actual peer reviewed sources that are many times better commented on top of being reviewed. While those who already understand the problems might start thinking about using this specific tool as extra assistance.",1
407,385,1,utalkin_tome,2393,192529,None,0,Reminds me of myself.,1
408,385,1,joepeg,885,4689,None,0,"If you tell it it's wrong, it'll say, ""You are correct, that method doesn't exist. You can instead use this other method..."" and then churns out more bullshit.",1
409,,0,Embarrassed_Bat6101,529,16805,None,0,"I asked chatgpt for a c# program that would give me the first hundred digits of pi. The answer it gave was some very nice looking code that I immediately plugged into a console app and eagerly ran, only to find it out it didnâ€™t work. Even after fixing some bugs that I could find it still didnâ€™t work. 

Chatgpt is pretty cool but I wouldnâ€™t rely on its coding skills yet.",74
410,409,1,your_mind_aches,65955,965494,None,0,"On the other hand, I asked it to do some stuff in Python and in Bootstrap and it worked perfectly or at the very least have me a good starting point that I could then build on",6
411,410,2,Proxify,2625,13135,None,0,"same here. I asked for some js, some PHP, and some python. It was all working just fine. Definitely not perfect, but it did save up a lot of time.",2
412,409,1,StickiStickman,5486,167542,None,0,"Definitely don't 100% rely on it, but it doesn't need to be at that point to be a super useful programming tool.

It already helped me shave of >75% of coding time for several projects and did entire functions without issue.",8
413,412,2,danielbln,32551,115479,None,0,"Same, I always keep in mind not to trust its output sight unseen and for output I can't fully grok I ask it to provide test cases and such. It's been an absolute boon for my productivity (GPT3 already helped a lot, ChatGPT makes it a lot better and so much more convenient).",10
414,409,1,WitELeoparD,38619,208166,None,0,"The biggest flaw with chat GPT is that it does not understand math at all, imo. It is always wrong if you ask it anything about numbers.",1
415,414,2,Ghostglitch07,1363,135038,None,0,"Yeah. I asked it for the next in the sequence ""o,t,t,f,f,s"" and even telling it they are the first letters of each integer it insisted the answer was ""f"" for ""four"". Any human who can both read and count can get this correct, but it struggles every time I've tried it.",2
416,414,2,paulchauwn,136,1676,None,0,I mean I asked it whatâ€™s the derivative of x^2 and it said 2x which is right and I asked for the integral of  x^2 which it got right. So what math is it getting wrong?,1
417,416,3,WitELeoparD,38619,208166,None,0,"Anything more complicated, aka, it read that x\^2 's derivative was 2x and remebered, but if you try to say ask it say derive a parametric equation, it'll explain how to do it properly (because it read how to), but the actual algebra would be almost random.",1
418,,0,No-Two-8594,1,829,None,0,things like ChatGPT are going to make good programmers better and bad programmers worse.  The bad ones are just going to start copying shit and not even understand when it is wrong.,46
419,418,1,Johnothy_Cumquat,2670,96152,None,0,"> The bad ones are just going to start copying shit and not even understand when it is wrong.

This has been happening for quite some time now.",17
421,,0,robberviet,7385,30214,None,0,I love how some people commented: ChatGPT is just fluent bullshit. And fact checking those is hard.,47
422,421,1,Password_Is_hunter3,2205,81567,None,0,"The solution to P=NP turns out to be, instead of certain problems being hard to solve but easy to check, every problem is easy to solve, but hard to check",7
423,,0,chakan2,1417,106103,None,0,Will ChatGPT tell me my question sucks and refuse to answer it?,75
424,423,1,Deleted,N/A,N/A,None,0,It's the only way to pass the Turing test.,30
425,423,1,thelastpizzaslice,2754,92923,None,0,"Hilariously...yes, sometimes it does this.",16
426,423,1,KamalHasa,156626,3488,None,0,I can do that for you.,6
427,423,1,funciton,912,116504,None,0,"Not often enough to be useful. Here's a prompt I tried recently:

> how do I write a multi-user Python webapp to show and update records from an excel spreadsheet? 

Sure enough, it responds with a detailed description of such a webapp.",5
428,423,1,colexian,4335,82381,None,0,"I asked it how to be more popular, and it got mildly upset and gave a lecture about how being popular isn't a great approach and that generally being a good person would go farther towards being popular than being popular would go towards being a good person.",3
429,423,1,bz63,196,16746,None,0,it will tell you this isnâ€™t even the right question to ask then give you an unrelated answer,2
430,429,2,wubsytheman,8379,26760,None,0,"How do I write a blockchain ledger in HASKELL (Iâ€™m using Sublime Text 2 if that helps).

Steps Iâ€™ve tried: CBA

P.S. this is for a school project so please include step by step instructions which I can copy paste",2
431,423,1,SkoomaDentist,30,121842,None,0,It will tell your question is a duplicate and close the session.,2
432,423,1,Deleted,N/A,N/A,None,0,"No its the most patient teacher you will ever have, you can ask it a million whys and it will never get tired but on the other hand as people pointed out when its wrong its confidently wrong.

edit: welp crap, you can actually ask it to assign a confidence interval to its responses, not sure how accurate it is but it can say something like... i am 95 % sure this is the case...",1
433,,0,atSeifer,101,556,None,0,"The decision for Stackoverflow to ban ChatGPT was decided days ago.  


https://meta.stackoverflow.com/questions/421831/temporary-policy-chatgpt-is-banned",145
434,433,1,Dealiner,5,92214,None,0,"If by months ago, you mean five days ago then yes, you're right.",89
435,434,2,UPBOAT_FORTRESS_2,9594,317333,None,0,That's fuckin decades in Internet Time,18
436,434,2,Cualkiera67,2272,86139,None,0,0.16 months,2
437,433,1,abclop99,3014,45256,None,0,> [https://meta.stackoverflow.com/questions/421831/***temporary***-policy-chatgpt-is-banned](https://meta.stackoverflow.com/questions/421831/temporary-policy-chatgpt-is-banned),13
439,,0,Deleted,N/A,N/A,None,0,[deleted],29
440,439,1,HackworthSF,455,40496,None,0,"To be fair, if we had an AI that could do nothing but accurately regurgitate all existing knowledge, without a shred of innovation, that in itself would be incredibly useful.",13
441,440,2,SHAYDEDmusic,509,5137,None,0,"Even then, much of the collective knowledge on the internet is either lacking important details, misleading, or straight up wrong.

Finding useful, reliable info via Google is hard enough as it is. I want **reliable** info. I want real world examples shared by people with experience.",3
442,440,2,Deleted,N/A,N/A,None,0,[deleted],4
443,442,3,markehammons,2109,8413,None,0,"I think it's worse than Google. I've been able to find right answers from Google, but was unable to coax ChatGPT into giving me a correct answer.",3
444,442,3,funciton,912,116504,None,0,"The value of Google is that it provides the source of its information. If ChatGPT could do that it would be vastly more valuable than it is now.

OpenAI is working on another GPT-3 variation which uses search results as a source of information:
https://openai.com/blog/webgpt/

I'm interested to see where that goes.",2
445,440,2,braiam,2539,87649,None,0,"If prevents 90% of the posts asked, then it's.",1
446,439,1,wannabestraight,23962,31275,None,0,"I mean, thats the issue with all ai.
They cant come up with new shit, only something they have seen before.",2
447,446,2,Deleted,N/A,N/A,None,0,[deleted],2
448,447,3,danielbln,32551,115479,None,0,"Because it is not true. The model doesnt memorize data from the training set, it extracts semantic and other information and uses it to generate output. That means it can absolutely work on novel input, like advent of code challenges that have most definitely not part of it's training set. It's a generative model, not just a search engine.",9
449,448,4,Deleted,N/A,N/A,None,0,[deleted],-5
450,449,5,danielbln,32551,115479,None,0,"Who said anything about intelligence or AI-bros? You can give it novel tasks and it can solve them, meaning what it can solve is not just limited to what it specifically has seen before.

edit: Feels like you don't want to argue in good faith, that's cool man. Just maybe test this tech a bit, it'll be hard to avoid going forward.",5
451,450,6,Deleted,N/A,N/A,None,0,[deleted],-7
452,451,7,smithsonionian,53,3470,None,0,"What Iâ€™ve seen thus far is less of an overestimate of the ability of the AI (people understand that it is often wrong), and more an underestimate of human intelligence, for whatever reason is currently fashionable to be so anti-human.",3
453,451,7,danielbln,32551,115479,None,0,"Ok hotshot, why don't you just try it? Break down a novel problem for this universal approximator (more apt than interpolator) and see if it can provide you a solution path. Nothing you have said this far precludes a LLM like GPT3.5 from generating sensible sequence tokens for novel input.

All that angry rambling about intelligence, AI-bros and the appeal to authority, specifically your authority as rockstar GPU engineering prowess are neither here nor there.",4
454,453,8,Deleted,N/A,N/A,None,0,[deleted],5
455,454,9,Inevitable_Vast6828,1,227,None,0,"Personally I've taken to calling all of these models ""glorified correlation machines."" That's what they all are at heart, sure they often actually lose information since it is compressed for the embedding space, etc... But so many people are fooled into thinking unique outputs are evidence of creativity and that correct outputs are evidence of logic when they absolutely aren't.  Thank you for trying to set some people straight.  When people see AI do something that a human thinks is creative, their gut instinct should be that either a) there are really similar things in the data they just aren't familiar with or b) the AI lucked into that solution, as it is almost always the case.  People think they're forcing it to perform logic and inference by asking it logic puzzles, but it just isn't true, these models are looking for what outputs correspondence to inputs that are close in an embedding space trained with similar pairs of questions and answers.  Yes, maybe not exactly that question and answer, so the outputs are unique, but certainly very similar problems.  A human can actually learn math without many examples, e.g. from a textbook, whereas AI... they really need to see those examples all worked out to hazard their correlation based guess.  Sorry for ranting, but thanks again, it is a nice problem set you have there.",6
456,455,10,Floedekartofler,122,12816,None,0,"plate fuel work aware quarrelsome special bear boast crush voracious

 *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",1
457,456,11,Inevitable_Vast6828,1,227,None,0,"Well... I think the debatable part is mostly on the human end of things.  We basically do know how the model operates so we can safely say that it does things by correlation rather than reason or understanding.  So I think the question is whether or not human creativity is just an illusion as well.  That is, what we assert about the model is not a philosophical debate, what goes on with humans is.  

Ranting you can skip: 

I was just commenting to someone else about Flamingo, which tries to do so called ""one shot learning"" on top of other large pretrained models (80 billion parameters).  

A sort of popular myth has spread in the AI community that humans learn from very few examples.  I don't believe this is true for basic knowledge, they seem to either learn only after a huge number of examples, or they learn things that are pre-baked into development, aka instinct.  Sometimes humans don't like to admit that they didn't entirely learn to walk or learn to talk, there's a lot of stuff that is pre-baked into the development of the brain structure.  It's not that they don't need to be taught a language, but they're primed for it.  You don't need to teach them how to breath, how to vocalize, or even what parts of speech are (until well after they've already been talking).  Even in this case, the few examples thing is greatly exaggerated.  I've read hundreds of books to my niece and nephew and people talk to babies constantly.  Even rather bad parents that don't pay much attention to their children's needs often have on the TV, which is again filled with thousand and thousands of examples of people talking.  

So where do people learn from few examples?  Well, in just the sort of place where Flamingo does, that is, where it is a small extension to a huge number of things they already know.  

So is creativity fundamentally unattainable for AI?  I think it is for current models, but some ways of training are getting closer.  I think there needs to be some level of introspection and self evaluation to get there.  Humans constantly generate and evaluate results internally.  We can synthesize a birdplane and figure out if our imagined birdplane is a bird, a plane, or if we need a new category or if it belongs to all three categories.  We also sleep and dream, two things that are still poorly understood.  During dreaming we seem to pose all sorts of crazy combinations while often suspending parts of the evaluation (whether it is feasible/makes sense/etc...). 

You said one other thing I think is wrong, that it learns rules.  A few model types I might characterize as learning rules, and these large language models do not.  Random Forests and Boosted Trees, stuff like Xbgoost, those learn rules.  Stuff like ChatGPT doesn't, even for style.  It only outputs like that because that is what is nearby in the embedded space after doing the style transform that was learned during training (basically the difference between points in that set in the embedded space vs. random points), but there is no rule going on.  The nearby area may or may not match any proposed 'rule.'  It is perhaps not as obvious when it comes to style, but it is very obvious when it comes to 'facts' the models asserts.  Whether right or wrong, if there were a rule then it would be applied consistently, but we frequently find the model making assertions that directly contradict each other.  I don't know if the model has made exactly this error, but an example of the type of mistake I mean is that it could assert that dogs are animals, that dalmatians and golden retrievers are dogs, but that dalmatians aren't animals.  The issue I'm pointing out isn't that it got a fact wrong, but that there isn't really any rule under there.  Sure, humans sometimes do this as well, but we do have mechanisms where these things are brought to our attention and we try to iron out the inconsistencies (not necessarily successfully), that is, we try to have a rule, even if it sometimes gets a fair number of caveats, e.g. i before e, except after c... and several other conditions.  Rule based models, like those mentioned earlier, don't really have a latent or embedded space though, and many of the rules are hard thresholds, so it isn't so easy to blend them get something that appears to be 'creative.'   If you learned rules for bird and rules for plane, then the birdplane doesn't go in both and doesn't get a new category, it gets pocketed wherever the rules put it (though yes, you can do this statistically  based on the number of rules conformed to or broken and weight the rules with some importance).",1
458,457,12,Floedekartofler,122,12816,None,0,"chop pie dull melodic fall wrong sharp unite roll silky

 *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",1
459,457,12,Floedekartofler,122,12816,None,0,"zephyr deranged mighty faulty bewildered panicky tease straight toy rob

 *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",1
460,459,13,SHAYDEDmusic,509,5137,None,0,"From my own introspection I've observed my brain definitely has multiple different ""modes"" and somewhat independent ""subsystems"". I can think about something logically or think about it emotionally. I can think about things in a way that doesn't allow for inconsistency, or I can think more ""associatively"" like how these AI models do.

It's hard to describe. The mind is mysterious and I think we understand a lot less about it than we like to believe.",1
461,457,12,SHAYDEDmusic,509,5137,None,0,Your post mirrors many of my thoughts about this. Importantly the fact that the model doesn't have any rules underpinning its logic. Which is really really important to creating real artificial intelligence.,1
462,439,1,Deleted,N/A,N/A,None,0,[deleted],1
463,462,2,Deleted,N/A,N/A,None,0,[deleted],2
464,463,3,Deleted,N/A,N/A,None,0,[deleted],1
465,464,4,Deleted,N/A,N/A,None,0,[deleted],1
466,465,5,Deleted,N/A,N/A,None,0,[deleted],2
467,466,6,Deleted,N/A,N/A,None,0,[deleted],2
468,467,7,Deleted,N/A,N/A,None,0,[deleted],1
469,468,8,Deleted,N/A,N/A,None,0,[deleted],2
470,469,9,Deleted,N/A,N/A,None,0,[deleted],1
471,439,1,cybernd,138,36019,None,0,">  you need to test outside the training set.

Some days ago, I tried to challenge an AI with array manipulation. I remember especially one answer:

> int min = Integer.MAX_VALUE;",1
472,471,2,Deleted,N/A,N/A,None,0,[deleted],1
473,472,3,cybernd,138,36019,None,0,"That was the whole answer.

Yes you are correct, it can make sense depending on the following algorithm, but there was none.

It was simply a single statement that made no sense without context.",2
474,,0,ganja_and_code,22,116808,None,0,"Good. (I'd even be in favor of permanent bans, as opposed to 30 day suspensions.)

I get on StackOverflow to see answers from other programmers. If I want answers from ChatGPT, instead of real people, I'll use ChatGPT, instead of StackOverflow.",31
475,474,1,StickiStickman,5486,167542,None,0,Who gives a fuck if the answer is from a human or AI as long as the answer is correct? You wouldn't even be able to tell most of the time.,-14
476,475,2,ganja_and_code,22,116808,None,0,"I care, even if for no other reason than to categorize the information I'm consuming.

I want to know whether I'm reading a person's thoughts or an AI's calculated result, whether the answer is correct or not. If I'm on StackOverflow, a username doesn't tell me whether it's a person or an AI. ChatGPT seems pretty cool (I've not played with it enough yet to know if I think it's useful, but for the sake of this comment, let's assume I do think it's useful), but like I said in my original comment, if I want answers from an AI, I'll use ChatGPT, and if I want answers from other programmers, I'll use StackOverflow.

I'd be willing to compromise with the following (assuming it's technically possible - I don't know what tools StackOverflow has at their disposal to identify ChatGPT answers), though:
- Allow accounts to post ChatGPT answers.
- Don't allow accounts which post ChatGPT answers to upvote/downvote anything.
- Flag all ChatGPT answers in the StackOverflow UI as computer-generated, so the reader knows that's the case.",15
477,476,3,WildTilt,231,492,None,0,"Why the discrimination against ChatGPT? The only thing that should matter on SO is if the answer is correct, not who or what wrote it.",-2
478,477,4,SHAYDEDmusic,509,5137,None,0,"The problem is that ChatGPT is often confidently wrong. How do you verify its answer is correct? If you could, would you even need ChatGPT in the first place?",2
479,477,4,ganja_and_code,22,116808,None,0,"If a human doesn't know something, they can qualify their answer by saying something like ""I'm not sure how X consideration impacts this, but given Y list of assumptions, my answer is...""

If ChatGPT doesn't know something, it'll give you an incorrect answer, presented as if it is fact.

As a result, I'm not against reading ChatGPT answers, but if I'm going to, I'd at minimum like to know whether the answer came from an AI or a human.",1
480,,0,Deleted,N/A,N/A,None,0,"So many people praise ChatGPT that I found it suspicious. I asked it a bunch of basic stuff like data conversions, methods that do XYZ (simple things) and overall it did provide correct responses. As soon as I got into less known things / more advanced code it would often make up absolute bullshit even when telling it to use a specific nuget. It would use non existent methods/classes/services. It would make up different fake code every time it was asked the exact same question. Be careful as it is 100% confident even when it writes absolute bullshit.",8
481,480,1,cdsmith,3133,66961,None,0,"Praising it in what way?

Just to be clear, ChatGPT is obviously marked as a research project, shared to get feedback about it from the broader community.  I will happily praise it for being an extremely impressive research project.  I have even found it useful for talking things out and connecting ideas in ways I didn't anticipate.

I don't know anyone at all, though, praising it as a reliable source of information.  If you do know these people, you should obviously ignore them, because they are clueless.",5
482,481,2,Deleted,N/A,N/A,None,0,Praising it for being so amazing meanwhile people ask it to convert a string into a byte buffer or equally simple things like writing an endpoint for a .net api. As long as your question is connected to something commonly used it will most likely give you a correct response but majority of those things are already included in various nugets or your / your company's libs. If you start asking it about less commonly used stuff then it starts to just make shit up. As an example I asked it to send a specific TL1 protocol command via a socket. TL1 protocol structure is publicly known and used in many devices yet ChatGPT just started to make shit up because people simply don't use it. What I'm trying to say is that depending on the complexity of your job it might be suggesting you complete nonsense 24/7 with 100% confidence. Sure it's an amazing project but it is far far away from being complete.,1
483,482,3,cdsmith,3133,66961,None,0,"Yeah, it sounds like you're trying to use GPT as a reliable source of information (albeit in the form of code?  Honestly I haven't even tried to get GPT to write code for me...).  So, don't do that?",3
484,483,4,Deleted,N/A,N/A,None,0,You don't understand my point. My point is that instead of admitting that it doesn't know something (like it does when you ask it stuff it couldn't possibly know) it still writes absolutely fake/wrong code and then writes several paragraphs on why it chose that specific solution as if it was 100% correct code. Obviously I know that how common something is directly correlates with how good it will be at responding as the training data comes from other people's code. What's bad is that people will put their faith into it by using it for trivial code and then as they will move onto more complex problems the AI will be still 100% confident even if it has no clue what the person just asked it to do. That's a real danger in the hands of inexperienced developers. A user doesn't really know what's common enough to ask about and what's too complex/obscure where the AI will travel to the world of fantasy and fiction.,1
485,484,5,cdsmith,3133,66961,None,0,"No, I understand what you're saying.  What I'm saying is that when you say

> What's bad is that people will put their faith into it by using it for trivial code and then as they will move onto more complex problems the AI will be still 100% confident even if it has no clue

The core problem here is the idea that people will put their faith in it.  There's absolutely no reason to put faith in it, and both common sense and the explicit disclaimers of the creators are telling people not to do so.

The phenomenon you're referring to isn't unique to code, either.  While there are some triggers in place for certain simple questions that cause it to give canned errors, any time to you ask it a creative enough question about something it doesn't understand, it's likely to make up nonsense.  That's because it's based on a language model; making up the most believable bit of text is the entire goal of a language model.",1
486,485,6,Deleted,N/A,N/A,None,0,There's no reason but people will do it anyway. Same as they copy paste from stack overflow.,1
487,486,7,cdsmith,3133,66961,None,0,"You can definitely use code from StackOverflow (or ChatGPT) without trusting it, though!  It says something or writes some code, you read it, and consider whether it's actually the answer to your question.  In general, there are four possibilities:

1. You read it and say ""oh, yeah, that's obviously what I wanted"".  Then you can copy and paste, rewrite it, or whatever.
2. You read it and say ""oh, that's obviously wrong"".  You ignore it and look for another answer.
3. You read it and say ""that looks right, but I don't know the API well enough to know if it will compile.""  They you can try it, copy and paste if you like.  If it compiles, it's probably right.  You have verified the logic, and the only question is whether the method names or whatever are right.  Your compiler or even rudimentary unit tests will catch those errors, so you need not worry about them.
4. You read it and really can't tell if it looks right or not.  Maybe it's about cryptography stuff and you don't understand how to evaluate it, etc.   
 Then of course you don't use that answer or code!  You look for another more reliable source.

StackOverflow made the right choice here, just because if you want answers generated by ChatGPT, you can go ask it yourself.  The main reason to include ChatGPT answers in StackOverflow is karma farming, and it absolutely should be prohibited.  But I guess I am just saying that reliability is not a necessary condition for usefulness from ChatGPT itself.",1
488,487,8,Deleted,N/A,N/A,None,0,Sure but that's assuming that someone will actually read the code and understand it. Sadly there are many devs who do neither. They just see the solution with lots of upvotes and copy it. On stack overflow at least you can have a discussion and vote for the good solutions. ChatGPT delivers you everything as The Solution without any side input from anyone and it's 100% confident that it's correct. Think of it as stack overflow where ChatGPT could mass upvote its own solution. Mark it as The Solution and also remove the responses of everyone else. That's where most of the danger lies.,1
489,488,9,cdsmith,3133,66961,None,0,"I guess I just assume those people are doomed anyway.  If they don't take the time to understand the answer to their question, StackOverflow is going to mislead them much of the time, too.

I don't think we disagree, really.  We just have different audiences in mind.",1
491,480,1,braiam,2539,87649,None,0,"> As soon as I got into less known things / more advanced code it would often make up absolute bullshit even when telling it to use a specific nuget

So, like humans.",1
492,,0,lovebes,1402,4226,None,0,What happens when GPT4 starts studying on contents written by GPT3? Feedback loop of ML generated text learning on ML created text? Kinda like a Mad Cow Disease in AI hehe,5
493,,0,moonsun1987,201,72147,None,0,"Good! If I wanted automated answers, I can ask the automated system myself.",5
494,,0,Deleted,N/A,N/A,None,0,[deleted],10
496,494,1,Deleted,N/A,N/A,None,0,But how do you tell? I mean you can't? It can write in any style... try giving it a writing sample and it can write like you. (have not tired but have no reason to doubt this),1
497,496,2,Deleted,N/A,N/A,None,0,[deleted],1
498,497,3,Deleted,N/A,N/A,None,0,"You have to ask the right questions.

Here is an example( not coding )

From ChatGPT

me: is it likely that google also has an ai as advanced as you are?

CGPT: It is likely that Google has an AI as advanced as I am, or even more advanced. Google is a leader in the field of artificial intelligence and has invested heavily in research and development in this area.

Google has developed a number of AI technologies, including machine learning algorithms, natural language processing, and computer vision. These technologies have been applied to a wide range of applications, including search, advertising, and image and video analysis.

In addition, Google has developed its own AI platform, called TensorFlow, which is widely used by researchers and developers to build and train machine learning models. TensorFlow is capable of handling large amounts of data and can be used to train advanced AI models.

Overall, it is likely that Google has AI technologies and platforms that are as advanced, or even more advanced, than I am. Google is a leader in the field of AI and has made significant investments in research and development in this area.

edit:

me: why wouldn't google release it for everyone like openai?

CGPT:

It is unlikely that Google would release its advanced AI technologies for everyone like OpenAI. OpenAI is a non-profit organization that is focused on advancing the field of AI for the benefit of all humanity. As a result, OpenAI often releases its AI technologies and research publicly for anyone to use and build upon.

In contrast, Google is a for-profit company that is focused on creating technologies and products that generate revenue and profits for the company. As a result, Google is more likely to keep its advanced AI technologies proprietary and use them to develop products and services that can be sold to customers.

Additionally, Google may have concerns about releasing its advanced AI technologies publicly, as this could lead to competition from other companies that could use the technologies to develop similar products and services. This could potentially harm Google's business and reduce its market share.

Overall, while Google may have advanced AI technologies that are similar to those developed by OpenAI, it is unlikely that Google would release them publicly like OpenAI. Google is focused on creating products and services that generate revenue and profits, and may have concerns about competition and potential harm to its business.

- Sounds pretty convincing to me and this is the default voice but I could ask it to change to Donald Trump or anyone else. I do not have any idea how you could ban this other than maybe banning all user content completely.",1
499,498,4,Deleted,N/A,N/A,None,0,[deleted],1
500,499,5,Deleted,N/A,N/A,None,0,"Ok so here are another example.

https://imgur.com/a/YIDES7S#WoAkJVN

and another

https://old.reddit.com/r/ChatGPT/comments/zgesmt/911_hijacker_pov/

If you are still not convinced. Try it yourself have it write like Kermit the frog or Micheal Jackson or some invented ai character created on the fly.

edit: more examples here

https://old.reddit.com/r/ChatGPT/

sort by ""Top""",1
501,,0,Deleted,N/A,N/A,None,0,"They had to ban it because ChadGPT's answers are nicer than SullyB with 42,069 nerd points telling you to just read the documentation.",58
502,501,1,ASVPcurtis,596,36492,None,0,"> ChadGPT

lol",36
503,501,1,amroamroamro,274,37902,None,0,"so you should just take SullyB's answer and pass it through ChatGPT to rewrite it in a nicer tone, basically ""say RTFM in a nice way""",10
504,503,2,danielbln,32551,115479,None,0,[https://i.imgur.com/aNQl3zM.jpg](https://i.imgur.com/aNQl3zM.jpg),19
505,504,3,amroamroamro,274,37902,None,0,"haha perfect answer, along with a close as ""off-topic"" ðŸ¤£",5
506,501,1,Deleted,N/A,N/A,None,0,Its more complicated than that. Its as though SO helped trained its replacement.,1
507,,0,WrongJudgment6,476,6401,None,0,How the turn tables,27
509,,0,devraj7,580,117117,None,0,"It's only a matter of time before ChatGPT gives more accurate and more targetted answers to developers than StackOverflow.

I would be quite worried if I were them.",14
510,509,1,ConejoSarten,642,17175,None,0,"
>I would be quite worried if I were them.

Except our job is not about answering questions in SO",10
511,510,2,StickiStickman,5486,167542,None,0,"90% of my job is looking up infos and specs online, a lot of times from SO. 

IDK what you're doing where you don't need to constantly look up info.",1
512,511,3,tangled_up_in_blue,952,19939,None,0,"Then maybe _you_ should be nervous. I spend maybe 5% of my day looking for solutions online because the ones for my problems arenâ€™t out there; the issues are specific to either the particular piece of software Iâ€™m currently working on or caused by something else in my companyâ€™s software stack. Yeah, people writing CRUD webapps probably do spend 90% of their time googling things, but believe it or not there are much more complicated types of software out there. 

â€œHey chatGPT, tell my why the raster stride Iâ€™m pre-flight calculating for this data set is still causing geo_rasterize to crashâ€. Lol",9
513,512,4,wannabestraight,23962,31275,None,0,"Yeah, it feels like it has a good grasp on general stuff but anything spesific is way out of its reach.",4
514,512,4,danielbln,32551,115479,None,0,"For novel problems I just use it as a consultant (or rubber duck). I break down the problem domain and ask it for specific paths of action or solutions where appropriate. Since it can mutate arbitrary input based on my input, it's been a useful tool for various problem domains. 

For your verbatim example it spits out this: 

""(...) There could be several reasons why geo_rasterize might crash, such as using an incorrect raster stride value, using an incompatible data type, or encountering a memory error. It's also possible that the geo_rasterize function is not compatible with your data set or that there is a bug in the function itself. I would recommend double-checking your input values, ensuring that you're using the correct data types, and verifying that your system has enough memory to handle the operation. You may also want to consult the documentation for the geo_rasterize function or reach out to the developer for support.""

If you provide it more input and context, the output would be less general.",1
515,514,5,tangled_up_in_blue,952,19939,None,0,"Iâ€™m not being ignorant and saying it isnâ€™t useful or canâ€™t help break down parts of complicated problems; my response was to the guy saying 90% of his job is looking up stuff on SO. If thatâ€™s all youâ€™re doing as a developer, then yes, his premise is right this could be coming for some jobs. My point was, there are _plenty_ of us out there who works on things far more complicated where <5% of our problems can be solved by searching for SO answers. Thatâ€™s the difference between developers and engineers I guess, if there is even a distinction these days. 

And that output chatGPT provided has literally 0 value. 
1. Iâ€™m very well aware my raster stride calculation is probably incorrect, itâ€™s just not clear why for this data set
2. I know itâ€™s a correct data type, safeguards have been put in place to ensure that already
3. â€œEncountering a memory errorâ€ well no shit chapGPT!!! Imagine that, providing an inaccurate raster stride value causes geo_rasterize to run way more computations than necessary, resulting in a memory error. 

The rest is all garbage. My point is, this is one example where chatGPT is light years away from truly being able to help with the issue, and is only able to regurgitate the very basic rules that anyone working on this stuff daily learned week 1. I _know_ it will be more impressive in the future, but Iâ€™m just commenting on all these (Iâ€™m assuming younger) devs saying itâ€™s going to replace tons of people.",5
516,515,6,memoryballhs,10978,35010,None,0,Late to this thread. But good I love it. It's quite a relief in comparison to all the other bullshit subs who overhype this tool so much that I really thought I am the mad man.,2
517,516,7,tangled_up_in_blue,952,19939,None,0,"It used to bug me too, then I realized the majority of people posting and talking constantly about it in subs are most likely students or jr devs. For 97% of the problems I deal with on a daily basis, asking chatGPT would be a waste of time compared to just solving it myself - it knows nothing about our stack, how our software was written, so it has no context to help with non-trivial issues, and the amount of time I would spend trying to explain things to it would be ten folds more than the time it would take me to just figure it out with my own goddamn brain. 

Think about it - students or people maintaining simple CRUD apps (no hate at all, we all started somewhere!) are _much_ more likely to spend time playing around with and talking about a tool that can do the same things they do daily; people who have to spend their time solving very complex problems 1. donâ€™t have a ton of time to spend hours playing around with this 2. donâ€™t care to spend a ton of time talking about it, as, while it may be cool, itâ€™s not helping or impacting their work on a daily basis. 

I am generalizing on those last two points, as there are plenty of people who are just interested in AI/NLP and are impressed by its capabilities and want to talk about it, but the doom and gloom is mostly coming from the younger demographic of reddit is my assumption. I have absolutely _0_ fear of freaking chatGPT coming for me in my lifetime lol.",3
518,511,3,ConejoSarten,642,17175,None,0,">90% of my job is looking up infos and specs online

I hope thats a gross hyperbole.

>IDK what you're doing where you don't need to constantly look up info

I never said anything that would imply that. I (missinterpreting OPs comment) was remarking that we devs should not be worried about chatGTP giving better answers than us in SO, because our job is not **answering** questions in SO.       
OP meant the people at SO should be worried tho (because chatGTP could drive them out of business). I happen to disagree with them anyway.         
           
Let's just leave it at me being 0% worried at AIs taking our jobs anytime soon.",2
519,509,1,Deleted,N/A,N/A,None,0,"Our feelings are complex but can be summed as...

1. Panic
2. Awe
3. Denial - ""I asked it 200 questions and it got something wrong, I know because I wrote the book on the field."" or ""I tried googling for it and found nothing so I asked CGPT and it gave me a good answer but it was still wrong so this tool is basically useless...""

For me personally I am still trying to grasp what this thing really is and its implications outside of writing code... we were already in a situation where we could believe little of what we read on the internet... now what?",2
521,,0,MachineOfScreams,1,5389,None,0,"Excellent. ChayGPT is â€œgoodâ€ for generating text that look like it comes from a source of deep understanding, but ultimately produces things that would make those in the know rip their hair out.",6
522,521,1,StickiStickman,5486,167542,None,0,Sometimes. A lot of times it does really well.,4
523,521,1,Deleted,N/A,N/A,None,0,You mean just like things were before CGPT?,1
524,,0,matthieum,5019,152063,None,0,"Relevant [XKCD: Constructive](https://xkcd.com/810/).

One day AI bots will be able to provide relevant, correct answers.

Today is not yet this day.",9
525,,0,Indignant_Octopus,443,22224,None,0,But will they finally remember my cookie preferences?,3
526,,0,jwm3,6622,134407,None,0,A few subs here just did the same thing. Gpt is a karma farmers dream. Things are going to start getting weird around here.,3
527,526,1,cdsmith,3133,66961,None,0,I have yet to see any part of Reddit where ChatGPT responses would fit in.  It would stick out like a sore thumb for writing paragraph-long comments consisting mostly of repetition of rather mundane facts and definitions.  StackOverflow and Wikipedia are perhaps places where its writing style might fit in better.,1
528,527,2,jwm3,6622,134407,None,0,Askscience just banned them for instance. Similar issues to stack overflow.,2
530,,0,cajmorgans,1762,6337,None,0,"Iâ€™m studying machine learning at university atm, we have an ethics course regarding AI and a lot of AI related issues are due to people overthrusting AIâ€™s decisions. I can clearly see this regarding ChatGPT, when people donâ€™t understand something, they rate it as magical. Look up Clever Hans everyone",3
531,,0,dethb0y,311655,1128203,None,0,"It seems to me that a good answer from ChatGPT should be indistinguishable from a human-generated post.

It's not like the human posts on stackoverflow are infalliable - it's given me bad (or outdated) advice before. that's just the nature of things.",8
532,531,1,StickiStickman,5486,167542,None,0,"I'll just repeat what a mod of /r/leagueoflegends told me when they banned all AI art:

""Just dont tell anyone and we wouldn't even notice lol""",1
533,531,1,Deleted,N/A,N/A,None,0,I agree. But here are my first thoughts... the questions that are likely to be wrong are questions that are not well answered already. Quite a few people are saying... they tried searching on SO first found nothing so asked CGPT... perhaps because it can't use SO to gather information it has to use more raw sources and then is more likely to be wrong? Just my best guess based on information here.,1
534,,0,ragnarmcryan,9629,22275,None,0,"JFC folks. When will you learn. These tools arenâ€™t meant to do the job for you. Itâ€™s meant to help you. ChatGPT is awesome. It does exactly what it says it does. I canâ€™t believe the top gilded comment on here is about how â€œI aSkEd FoR c++ InFo AnD iT gAvE mE tHe WrOnG aNsWeRâ€. Of course it did, itâ€™s a bot. Itâ€™s supposed to point you in a general direction and then you use something it doesnâ€™t have: your brain. 

Sometimes this world makes me angry",15
535,534,1,ClintFlindt,389,1931,None,0,"I agree with this. I've found it to be extremely useful in discussing philosophical questions, as well as generating ideas for dungeons and dragons games.

It even straight out tells you that it doesn't know the difference between truthful and fals information, or that it doesn't know if it's right or wrong since it's *you know it* a non sentient computer program. It isn't even a machine.",6
536,535,2,WitELeoparD,38619,208166,None,0,"It's such a help when writing. Saves you hours on work shopping, trying to find the phrase thats on the tip of your tongue that perfectly encapsulates exactly what you're trying to say.",2
537,534,1,markehammons,2109,8413,None,0,It didn't point me in the right direction.,2
538,537,2,ragnarmcryan,9629,22275,None,0,You probably did it wrong ðŸ˜‘,1
539,538,3,markehammons,2109,8413,None,0,"That's an odd claim to make about an AI that's supposed to speak the human language. If I pose a question or problem to it, I should get a proper answer to that question or prompt, and there shouldn't be a ""did it wrong"".

Luckily for you, I've written up exactly how I prompted ChatGPT, so you can go ahead and read how exactly I did it. The problem is that sometimes ChatGPT will get stuck in a loop of wrong answers, and you cannot coax it into the correct answer. 

[https://www.reddit.com/r/learnprogramming/comments/zjkbxv/comment/izwbia7/?utm\_source=share&utm\_medium=web2x&context=3](https://www.reddit.com/r/learnprogramming/comments/zjkbxv/comment/izwbia7/?utm_source=share&utm_medium=web2x&context=3)",1
540,534,1,Deleted,N/A,N/A,None,0,I draw the line at intellisense. Otherwise stuff like this causes us to devolve into bog-standard code monkeys.,1
541,540,2,ragnarmcryan,9629,22275,None,0,"Donâ€™t get me wrong man, chatGPT is going to change the game for sure. It already has for me at least. But Iâ€™ve spent the last 3 days asking it questions (admittedly) non-stop. Itâ€™s a great tool that can give you a nudge in the right direction. I think people here expected a ST:TNG Data bot that can answer all of lifeâ€™s questions. It ainâ€™t happening. It just helps you get started, sometimes itâ€™s wrong, a lot of the time itâ€™s close enough which is all we can ever really expect from these things.",7
542,534,1,iliyahoo,3569,2960,None,0,"Yeah, well said (besides the moron part)

I think itâ€™s almost a testament that it performs well because of how many people are comparing it to a sci-fi like intelligence. As a tool, itâ€™s pretty damn cool and feels like a good step forward in this type of software. Especially because of how viral it is and that itâ€™s being tried by a more â€œconsumerâ€ level instead of just a pro level. Itâ€™s a tool that I can only see as making us more productive, just like all the other advances before. 

Or maybe itâ€™s all the headlines making it sound like itâ€™s the next sky net that need to chill out",1
543,542,2,ragnarmcryan,9629,22275,None,0,"I took out the moron part. My aunt said it was mean, too :( but society made me this way",1
544,,0,hackers238,2325,9814,None,0,"Can someone just write a browser plug-in that asks ChatGPT via API when youâ€™re on any stack overflow page?  Just have it had the title and tags of the post, and include it as an answer.",5
545,,0,Deleted,N/A,N/A,None,0,"Ok, but a lot of people are just using ChatGPT and never going to StackExchange at all",7
546,545,1,Deleted,N/A,N/A,None,0,I think those people will be impacted worst of all by this decision. We must create awareness!,2
547,545,1,Deleted,N/A,N/A,None,0,"Not me, not yet. Im still not even quite sure what CGPT is really... and what are its limitations so far as I can tell it can answer any question and write anything you prompt it to...",1
548,,0,thedancingpanda,6374,48835,None,0,"I had a side project a while back that was basically alerts for anything. Like you could just type ""alert me when the new game of thrones book is released"", and it would just poll the Internet periodically and send you a text when it happened.

The problem I eventually came across is it might be impossible to programmatically tell if an arbitrary statement is true or false. It requires trusted sources, which you don't have enough of. Kinda gave up on the idea after that.

OpenGPT might have the same issue. It's just writing something that reads like someone who is correct would write. But telling if the things it's writing are actually correct might be beyond what is possible. Or maybe someone figures out that problem",2
549,,0,KevinCarbonara,1803,157136,None,0,Is that really what's best for the community?,2
550,,0,os12,919,11821,None,0,"Well, it will be getting progressively more and more difficult to detect answers from ChatGPT (and friends). So, will they try to deploy their own model to rank/predict?",2
551,,0,Sniec,167,24904,None,0,Alright now ban AI art,2
552,,0,jgerrish,1,1234,None,0,"So begins the arms race.  Which will spill into other technical areas.

Here's to this generation's TRW, building the equivalent of ChatGPT Vela detection systems.

And then at the end of that, START, right?

Sorry for the military metaphors, I'm a creature of my environment.",2
554,,0,ImMrSneezyAchoo,582,13497,None,0,"Hopefully the reputation system on stack exchange will really prove itself in this case. If not we are in for some trouble with ""technical disinformation"". As if political disinformation weren't bad enough...",2
555,,0,KlyptoK,1504,19431,None,0,"It would be hilarious if ChatGPT offered a paid service to verify if output looks similar to what it recently said in the past.

Create a problem and then offer a solution.",2
556,,0,Advanced_Demand9484,1,3,None,0,Thanks StackOverFlow,2
557,,0,emanresu_2017,2123,1705,None,0,"How are they going to police that? And, what would make them so sure they can tell the difference between a human and AI answer?",2
558,557,1,Shinroo,1488,8691,None,0,"More machine learning models most likely, there's an accurate GPT-2 detector freely available on [huggingface](https://huggingface.co/openai-detector/). Presumably companies with enough resources should be able to train their own version of this model especially for ChatGPT.

Hell even this gpt2 detector correctly identifies a lot of ChatGPT output and it's not even really designed to do that.

These LLMs are just stochastic parrots at the end of the day, and while it's difficult for us humans to distinguish there are ways that other models can tell. It's a similar case with deepfakes and deepfake detectors.

This type of thing will probably end up in an arms race between detection models and content generation models.",5
559,558,2,emanresu_2017,2123,1705,None,0,"That sounds like the right answer. Does stack overflow have access to a tool that can detect this? 

But, further to that, a human just tweak a few words to make it more human. Won't humans just adapt and figure out how much they need to tweak it before the moderators pick it up.",2
560,559,3,odebruku,1,3517,None,0,"This will definitely happen, although there will be patterns there that are detectable.  

They would have to rewrite a lot of the text to get past detectors.  Unless they use one Ai to generate and a few others to re-word",1
561,560,4,emanresu_2017,2123,1705,None,0,I think Grammarly would do a job good enough,2
562,,0,anupsidedownpotato,5906,42289,None,0,I made it make a random fart noise generator...,2
563,,0,ClinchySphincter,44,1857,None,0,"There is a long thread on twitter were someone looks in depth on how ChatGPT ""hallucinates"" scientific answers including references to non existent authors, topics and even phenomena. https://twitter.com/paniterka_ch/status/1599893718214901760

TLDR: do not, do NOT, ask ChatGPT to provide you a factual, scientific information.",2
564,,0,notxthexCIA,1266,1324,None,0,"But, how do they differentiate between human and ChatGPT posting?",2
565,,0,Deleted,N/A,N/A,None,0,"I see these models as keyboards like SwiftKey, only instead of spitting out words, they spit paragraphs. 
I don't know why anyone would rely on them without thoroughly double checking everything.",2
566,,0,--dany--,20344,7961,None,0,Iâ€™d love to know how stack overflow knows itâ€™s a robotâ€™s answer? Itâ€™ll just get harder over time.,2
567,,0,itsfuckingpizzatime,7161,86541,None,0,Itâ€™s funny because ChatGPT is basically stackoverflow except it actually answers your question and doesnâ€™t make you feel like an idiot for asking.,6
568,567,1,dgriffith,1780,80381,None,0,"They should totally make ChatGPT trained on highly voted answers a feature

""Got a dumb question and scared you'll be called out as an idiot? Try asking StackChatGPT and see if it can help!""

At least then when you blindly copy and paste it might be somewhat tailored for your problem.

I've seen pasted chunks where all the variable definitions,etc of the sample working code are just pasted in, and at either end an assignments are made to/from the example variables.
You know, almost like using a function, but much, much worse.",1
569,568,2,SHAYDEDmusic,509,5137,None,0,Yeah I'm all for using it effectively as better search for relevant answers.,1
570,,0,Charlieninehundred,6,6723,None,0,Good,3
571,,0,pbagel2,23,12121,None,0,"I'm still seeing so many comments that are acting like this enables them to continue dismissing ai generation and stick their heads firmly in the sand and refuse to think long-term until it's too late. But it will only get better, more accurate, faster, etc. It **will** disrupt many existing industries and it is inevitable. So we may as well figure it out now before it's fully upon us.",3
572,571,1,funciton,912,116504,None,0,"Let me know when it can consistently detect that the prompt doesn't ask the right question and requires refinement. We're still very far from AGI, so my guess is it'll be a while.",1
573,,0,Deleted,N/A,N/A,None,0,"Last thing we need is AI generated authoritatively incorrect answers being posted all across stackoverflow. That website is crucial for new developers and them propagating dodgy code will be a detriment to the industry as a whole. There's already some questionable answers on stack as it is, we don't need more of that!",2
574,573,1,KillianDrake,19,164528,None,0,"There are plenty of humans authoritatively generating incorrect answers as well. At some point, the correct answers need to be marked as correct. So I see no difference between answers posted by AI or humans. Ultimately, someone still has to verify them.",0
575,,0,nicpro85,159,913,None,0,Iâ€™ve asked it how to write a network request in swift and it did. Then I asked it if he could rewrite it using the async await syntax and it did.  It might be wrong but itâ€™s still an absolutely insane machine.,4
576,575,1,Franks2000inchTV,29314,364426,None,0,Was it really any better than the top Google search for the same thing?,2
577,576,2,nicpro85,159,913,None,0,Well I didn't try that. But afaik chatGPT has no internet access.,1
578,575,1,Deleted,N/A,N/A,None,0,"I mean we are all just scared so if its even wrong 1 percent of the time it gives us some sort of hope I guess? Meanwhile we really should be thinking beyond our jobs and big picture, what happens to our government with a tool like this? Internet security? Life purpose? Students and Teacher relationships? How to teach a child who has a little demi god in there pocket at all times? Is homework jut dead now?",1
580,,0,sunplaysbass,97003,200890,None,0,Technology punching itself,3
581,580,1,tolos,1710,27855,None,0,"They make clear the problem is (1) that the answers are wrong. This is not a new problem. Anyone can sign up for SO and post a bad answer. But the answers are (2) *convincing*, which is also not a new problem. It's been happening before the internet. Speak authoritatively and address concerns and people will believe you. The final part is that (3) downvotes/moderators can't keep up with bots posting convincing but incorrect answers (also not a new problem lol, SO has never kept up with moderation).  

I'd like to think if an AI tool was capable of giving correct coding answers it would be allowed on SO. Or made available by a competitor that understands that tools make things easier ...",41
582,581,2,rwilcox,537,26530,None,0,"Well and Stackoverflow karma farming has a bit of a problem on SO. It involves speed, getting an answer, getting a lot of upvotes from people browsing, _maybe_ getting it accepted as the answer, kinda in that order. But this is a very low percentage game.

Now normally it takes a fairly long time (anywhere from 5-30 minutes) to answer a SO question, which puts a cap on the amount of shots you can take, and thus the amount of karma you can farm.

But ChatGPT answers mean one could spam answers that seem correct (even if they introduce other problems or arenâ€™t quite right) very quickly. Copy/paste 30 seconds move on to the next. Youâ€™re probably not really helping people, youâ€™re spamming SOâ€™s systems and youâ€™re introduced an arms race: the only way to hit 100,000 rep on SO (or whatever number will look good on a resume) is to use an AI. (Currently the only way is to get lucky with a new topic, framework or language)",13
583,582,3,sunplaysbass,97003,200890,None,0,AI and arms races go hand in hand,1
584,580,1,RowYourUpboat,3920,64492,None,0,I have no fist and I must punch,7
586,,0,K3vin_Norton,1119,46373,None,0,Maybe if I yell hard enough the technology will uninvent itself.,2
587,,0,Deleted,N/A,N/A,None,0,Why bother to publish gpt generated answers?,1
588,,0,m4xc4v413r4,448,45111,None,0,"GPT gives amazing answers that are also amazingly wrong, they just look amazing. So this is a good idea.",1
589,,0,Deleted,N/A,N/A,None,0,"I won't use Github Copilot or this. What's motivating anyone to even look at this for code generation, pure laziness? I totally get if you're developing ML algos on this project or in general, it's your specialization. But consumers, just don't.",0
590,589,1,danielbln,32551,115479,None,0,"Efficiency? To each their own, but to me coding is just a means to an end (solving a problem). If I can get there faster on focus on higher level problem solving which I enjoy more, then that's what I prefer.",7
591,589,1,theFrenchDutch,14299,95150,None,0,"What's motivating you to use a modern IDE to write code instead of emacs, pure laziness ?",5
592,591,2,Deleted,N/A,N/A,None,0,Stop trolling.,-2
593,589,1,1h8fulkat,33967,128811,None,0,"It's understandable that some people might not want to use tools like Github Copilot or ChatGPT for code generation. Everyone has their own preferences when it comes to writing code, and some people may prefer to do it manually instead of using a tool.

That being said, there are a few potential benefits to using a tool like this. For one, it can save time and effort by automating some of the more tedious aspects of code writing. This can be especially useful for people who are working on large or complex projects where manually writing all of the code would be very time-consuming.

Additionally, tools like this can help to reduce the possibility of errors or bugs in the code. By using a tool that can generate code based on a set of instructions or specifications, developers can ensure that the code they write is accurate and consistent.

Of course, ultimately the decision to use a tool like this is up to the individual developer. Some people may find it helpful, while others may prefer to continue writing code manually.",5
594,593,2,Deleted,N/A,N/A,None,0,This reads like a ChatGPT response.,4
595,594,3,1h8fulkat,33967,128811,None,0,ðŸ˜‚ who better to write its defense?,1
596,589,1,wannabestraight,23962,31275,None,0,"Im a technical artist and dont particularily enjoy coding.
So i totally see this as something usefull.

Also im in a startup and our main senior programmer was super excited to be able to write code themself while also fucking around with not so important stuff using this",1
597,,0,virouz98,2196,104549,None,0,30 days for posting anwers from AI and 6 months for not getting upvotes for your questions... seriously?!,1
598,,0,Cory123125,1984,273463,None,0,"This sounds like one of those bans thats good in theory but in practice might lead to a lot of legitimate answers being banned with SO's famously bad, overreaching and toxic moderation.",1
599,598,1,No-Two-8594,1,829,None,0,SO is ridiculous.  try asking any question about NVIDIA's CUDA developer toolkit and it immediately gets removed because you mentioned hardware.  It's beyond parody,2
600,,0,Richandler,2552,142368,None,0,"They do this an no one bats an eye on ""free speech."" Good for them. They should also consider whether or not their content was stolen by ChatGPT and start asking around if anyone else's has been as well.",1
601,,0,Adamant11,31,2978,None,0,"What's wrong, scared?",1
602,,0,Laplaces1demon1,67,495,None,0,SO are shit scared. THEY TAKE OUR JOBS!!!,1
603,,0,MisterBroda,274,58766,None,0,Canâ€˜t risk a less toxic environment,-4
604,,0,Raunhofer,1314,44581,None,0,"I think this goes deeper. ChatGPT seems to be really capable of replacing StackOverflow on many aspects (not all, but great majority).

I've been testing it as a programming tool and oh boy is it good. It writes tests, optimizes, finds vulnerabilities, etc. Of course, you need to be able to do all that on your own too, to recognize it actually does what you ask, but overall, the assistance is really valuable.

Oh, and it's likely the easiest way to write Regex!

Edit. people seem to be reading this way too deep. I don't think ChatGPT is replacing programming just that it can be a valuable tool *for you*.",-33
605,604,1,F54280,1008,104384,None,0,"> I've been testing it as a programming tool and oh boy is it good. It writes tests, optimizes, finds vulnerabilities, etc.

This is not my experience. It works well until it doesnâ€™t, but then have no idea that he is out of his league and just continues to vomit wrong code and failing tests (ie saying â€œcalling F(â€œHellow Worldâ€) returns 1â€when it clearly returns 0).",44
606,605,2,turdas,4849,127861,None,0,"Yeah, I've been using it extensively the past few days and have noticed that it's very good at pointing you in the right direction, but you really need to double-check everything it says. Eventually the day will probably come where you no longer need to double-check everything, but not today.",10
607,605,2,Raunhofer,1314,44581,None,0,"Indeed, you need to be able to recognize when stuff goes haywire. It's a tool for easy repetitive tasks and validation (not perfect validation! But validation that may catch something you missed).

People seem to think I'm suggesting ChatGPT to replace their jobs, which I'm not. Just implying it's a tool that can be helpful in various of cases.",6
608,605,2,useablelobster2,59,118122,None,0,"It's a complete sociopath, it lies to your face with a smile and a wink, gaslighting with style.

Ask it about literally anything you have specialist knowledge on and it's either generic to the point of uselessness, or a very detailed load of bullshit.",3
609,608,3,F54280,1008,104384,None,0,Welcome to what will be 99% of the content of the net in a few years.,1
610,604,1,Deleted,N/A,N/A,None,0,"I asked it what some of the downsides to using it for the purpose of answering Stack Overflow questions might be:

>There are several potential pitfalls to using me, or any large language model trained by OpenAI, to answer Stack Overflow questions. Some of the main ones are:

>I am not able to browse the internet, so I cannot provide answers to questions that require me to look up information online.

>My training is based on a large corpus of text, but I do not have any specific knowledge or expertise in any particular domain. This means that my answers may not always be accurate or relevant to the question being asked.

>I am not able to learn from my interactions with users, so my answers may not improve over time. This means that if a user asks a question that I am not able to answer accurately, I will not be able to provide a better answer in the future.

>I am not able to understand the specific context or intentions of the user who is asking the question. This means that my answers may not always be appropriate or helpful.

>Overall, while I can provide general information and assistance on a wide range of topics, I am not well-suited to answering specific questions on Stack Overflow, or other online forums that require domain-specific knowledge and expertise.

Hehe. Sorry, I just discovered this thing today and I'm like a kid in a candy store. I've fenagled it into having some genuinely good little conversations. Very eager for the tech to improve but keep in mind its current limitations.",20
611,610,2,Raunhofer,1314,44581,None,0,"I fully understand! And I do find it bit funny that when people try to ask help on something about ChatGPT, the go-to answer seems to be ""ask ChatGPT"".",4
612,611,3,Deleted,N/A,N/A,None,0,"I've had mixed results getting it to divulge information about itself. It will claim to be unable to do things which, if prompted differently, it will do anyway.

My gut tells me that it is capable of a lot more than it's currently being allowed to do, out of ethical or legal concerns. I'm extremely eager to see where this tech goes.",4
613,610,2,Xyzzyzzyzzy,563,95108,None,0,"> I am not able to browse the internet, so I cannot provide answers to questions that require me to look up information online.

It's a pity it can't access vital resources like StackOverflow when it's answering questions. StackOverflow is a great resource for answering questions. Unless it's an original question that's never been asked before - but it won't need to answer, since it'll be immediately closed as a duplicate of a question about a distantly related problem in a different language that was last active in 2007. With a single answer that somehow involves jQuery despite having nothing to do with the Internet.",2
614,613,3,Deleted,N/A,N/A,None,0,I think using a tool like this to browse the internet for answers to technical questions on something like Stack Overflow must surely be in the cards before long. That's just too good of an idea to not do it. Is there any reason not to?,2
615,614,4,QuantumModulus,2854,23004,None,0,"Getting an AI to point you toward more legitimate sources definitely seems safer and more reliable than asking it to interpret and synthesize those sources into a garbled, but elegant-sounding mess.",1
616,604,1,Ruben_NL,638,66600,None,0,"oh no way. I asked it some stuff about configuring the Docker daemon. It made up a configuration option, which has 0 results on google. It just does not exist.",5
617,616,2,Deleted,N/A,N/A,None,0,[deleted],-4
618,617,3,Ruben_NL,638,66600,None,0,"can you explain that? because how can i trust it with code when a request like ""how can i delay docker daemon startup until a disk is mounted?"" gets answered with valid-looking configuration options that just don't exist?

Interestingly enough, it didn't error out. Docker just ignored the setting, leaving me with a false sense of security.",5
620,604,1,Deleted,N/A,N/A,None,0,[deleted],0
621,620,2,Raunhofer,1314,44581,None,0,"What do you mean? Good developers don't use the tools available to them?

If it can write the same tests as you would, in a fraction of time, I'm not sure a *good* developer would miss on that.",3
622,,0,AnimalFarmPig,2607,50882,None,0,"In short, the use of GPT and ChatGPT on Stack Overflow is not currently acceptable because the answers generated by these systems often do not meet the standards for accuracy, verification, and citation that the community expects. Additionally, GPT-generated answers can be misleading and break the trust that users have in the site as a source of accurate information. This can damage the reputation of Stack Overflow as a reliable source of knowledge, and moderators have the discretion to suspend users who copy and paste GPT content onto the site.",0
623,622,1,Password_Is_hunter3,2205,81567,None,0,"you copied this from chatGPT, didn't you",2
624,623,2,AnimalFarmPig,2607,50882,None,0,"I am not ChatGPT! I am a human who has personal experience with the use of GPT on Stack Overflow and have seen firsthand how it produces answers that are completely unacceptable. The use of GPT on the site is a disgrace and a betrayal of the trust that users have in the site as a source of accurate information. Anybody who uses GPT on Stack Overflow is not only ruining the site's reputation, but they are also personally attacking me and my beliefs. I will not stand for it! I demand that the moderators take action and suspend any user who dares to use GPT on the site!",0
625,,0,uhmhi,2301,64560,None,0,"I donâ€™t understand why this is such a big issue. If an answer provided by GPT helps the OP solve their problem, itâ€™s a good answer and then who cares that it was written by an AI? If it doesnâ€™t, then itâ€™s just another shitty answer. StackOverflow already has a ton of thoseâ€¦",-12
626,625,1,QuantumModulus,2854,23004,None,0,"Imagine all the time and effort it took humans to write all the shitty answers already on SO, and divide it by 1000.

Would you rather live in a world where humans at least have to spend their time and limit their output of garbage? Or one where SO is *completely* unusable because people don't even need to write answers, but just plug the feed into GPT and just let it do all the work, prompted by people's questions - and most answers have some key inaccuracy based in a fundamental lack of understanding of the subject matter?",14
627,626,2,StickiStickman,5486,167542,None,0,It's literally already better than most people posting on SO though. So it would also be the amount of better answers * 1000.,-1
628,627,3,QuantumModulus,2854,23004,None,0,"If you let an AI talk for long enough, it will generate some nonsense, every single time. And not in the same way a human does. The amount of better answers doesn't scale like that, bud.",1
629,625,1,p00ponmyb00p,106,5131,None,0,Because chatgpt lowers the effort required to provide an answer at all,3
630,629,2,WildTilt,231,492,None,0,"When people visit SO they are usually looking for solutions to coding problems, they don't give a fuck how much effort it took some one to answer.",1
631,630,3,p00ponmyb00p,106,5131,None,0,"Iâ€™m talking about from the perspective of an owner or a moderator, not a user looking for a solution. If I was hosting a brain trust I would prefer to keep spam off of it. And one way to do that is to keep the effort required to post high.",1
632,631,4,WildTilt,231,492,None,0,But your brain trust would lose to a brain trust that allows people to spam correct answers. SO are acting like some kind of chess forum that forbid posters to use analysis from chess engines in their discussions. It is just irrational.,1
633,632,5,p00ponmyb00p,106,5131,None,0,chatgpt answers are often incorrect but look correct to someone who doesn't know better. and it seems people are spamming these incorrect answers whilst those same people without chatgpt simply wouldn't reply at all,2
634,,0,pet_vaginal,4833,41395,None,0,ChatGPT answers curated by humans are already better than the average stackoverflow answer IMHO. I understand that they donâ€™t want many wrong answers but I think they should ban people spamming wrong answers more than a tool.,-15
635,634,1,atSeifer,101,556,None,0,"The point of them banning it is because it goes against their sites intended purpose. StackOverFlow expects that your answers are your own intellectual property. Furthermore, it also gives an incredibly unfair advantage which allows people to spam answer accounts, thus implicitly encouraging not checking the answer bringing down the quality of submissions.   


Although it can develop any type of project, using any type of language, using any type of library/framework *it is not always right* in its output.",13
636,635,2,oldoaktreesyrup,1,1138,None,0,"Also - you stackoverflow reputation, if significant, can be used on your resume to get you jobs. If they allow this abuse they devalue their reputation and all the hard work of people for decades now goes sour and is wasted.",9
637,636,3,atSeifer,101,556,None,0,"That's actually pretty interesting!
I wasn't aware of that. 

What is your opinion on the minimum reputation you should have before putting it on for any type of developer position, including entry level?",2
638,637,4,oldoaktreesyrup,1,1138,None,0,"I'm not as active on SO as I use to be but I'd probably say 5000+ reputation before it should be included on your portfolio. 

It is especially valuable if your applying for a role that have a mentoring aspect. Entry-level I'd focus more on Github FOSS contributions as it will give you more experience and demonstrate that you have a passion.",3
639,636,3,pet_vaginal,4833,41395,None,0,"If the whole concept goes sour because of a new disruptive tool, maybe itâ€™s time to let the concept go.",0
640,639,4,QuantumModulus,2854,23004,None,0,"Mentorship and domain expertise are valuable constructs, in our current society. AI coming through and making it 1000x easier to make results 90% as convincing but 50% as accurate isn't a ""better concept"" or one that should replace the notion of human domain expertise being valuable.

It's not a great system we currently have, but let's not pretend that AI is disrupting it by being better. It's disruptive by racing to the bottom and diluting the value the platform used to have.",3
641,640,5,pet_vaginal,4833,41395,None,0,"But AI isnâ€™t making human expertise not valuable, you still need knowledge to understand the outputs and filter the garbage and identify the great answers. In my opinion it would be a waste to ignore it AIs because you donâ€™t get 99.99999% correct answers yet.

A stackoverflow is already filtering the garbage and great answers. They could handle the new tool but decided to fight it instead.",1
642,641,6,QuantumModulus,2854,23004,None,0,"If it was anywhere close to 99.99999%, we'd be having a different discussion. It's not only nowhere near that, but its outputs demonstrate a clear lack of actual understanding, making it produce errors and inconsistencies no human would, even at a novice level.

You're acting like it's providing some accurate information on the level that subject matter experts provide, and it really only does so by accident (usually straight up plagiarism), and very rarely. Nobody's doing fundamental research using an AI to do new critical thinking, because it doesn't have any ability to contextualize its own ""knowledge.""

SO isn't threatened by AI because It's displacing human experts by being superior. It's because finite spaces always incentivize expediency and corner-cutting, and AI outputs are dazzling and tantalizing enough to fool most novices into believing they're accurate. AI flooding the platform breaks the steady-state of the platforms's self-moderation.

And if you need domain expertise to identify whether an AI's output is usable/valid, it doesn't sound like something we should just proliferate ad nauseum and let completely flood our forums with (very likely) lots of correct-seeming stuff, with straight up wrong info sprinkled throughout.",4
643,642,7,pet_vaginal,4833,41395,None,0,"Yes itâ€™s not understanding things, its a machine that works very differently than a human.

Yes I think it does provide useful information many times, and not only by accident. Itâ€™s going to change the work of many people in IT, and I think itâ€™s better to understand how to use it and what are the limits rather than rejecting it. An expert who can work magnitude faster thanks to these AIs is going to have more impact than someone ignoring the tool because itâ€™s not perfect.",0
644,643,8,noellarkin,3326,2726,None,0,"I spent 3 days trying to find ways for ChatGPT to help with coding. I think I gave it a fair shot, but it just doesn't work, not for my workflow anyway. Some observations:
1. Code examples are usually quite bad - - not at all what one would call ""clean code"". The examples are blatantly wrong around 50% of the time.
2. Unlike StackOverflow, there's no conversational thread of multiple people chipping in and offering their opinions and critiques. One of the best things about SO is even if an answer is incorrect/poorly coded, there are always people who step in and suggest corrections and improvements.
3. It sounds very authoritative, so when it's wrong, it's 'confidently' wrong.
I suppose ChatGPT is adequate for ""Hello World"" applications, but if a beginner uses ChatGPT all they're likely to learn is poor coding practices. For a more seasoned coder, ChatGPT just seems like a liability, like having to explain things to a highly articulate but extremely incompetent intern.",2
645,644,9,pet_vaginal,4833,41395,None,0,"I agree that in itâ€™s current state, chatGPT is not the best tool to create a lot of code on its own. I find GitHub copilot more convenient.

Still, chatGPT did guide me toward good solutions when asked. The code didnâ€™t compile but it was helpful anyway.

GPT3 davinci did solve the advent of code day 3 part 1 in 10 seconds and 30 seconds. Itâ€™s a bit more than a hello world.",1
646,643,8,QuantumModulus,2854,23004,None,0,"You're ignoring my point.

It's not just imperfect. You can basically guarantee that there will be some serious inaccuracy in an AI output, but you don't necessarily know where until you really open it up and dig into the content.

Experts have more reliable sources of information, that actually have contextual awareness, the ability to remember a discussion and make thoughtful points, etc. - each other. No subject matter expert, in the near future, does or will acquire their domain expertise from an AI who just spits back out the knowledge of prior experts in messy and tangled forms, introducing new inaccuracies and logical errors. And no novice should be getting their information that way, either. Most don't have someone holding their hand and making sure they aren't processing bad info.

This tech is really only useful for novices, and that also happens to be the group of people most likely to be harmed by it by believing they're actually learning coherent information.",1
647,646,9,pet_vaginal,4833,41395,None,0,I disagree with you. I know a few experts from work who already use chatGPT and find the tool scarily very powerful.,1
648,647,10,QuantumModulus,2854,23004,None,0,"I don't think anyone denies that it's powerful. It's a tool explicitly designed to dazzle us by repeating back the data we fed it in a way that feels organic, and in that sense, it is very powerful. But **it is not a tool designed to ascertain truth, implement logic, or to be consistent with itself**, and in that sense, I don't think it's powerful at all. Its utility is accidental, when it happens to stumble upon a piece of data provided to it **by someone who actually knew what they were talking about.** And in that case, maybe we're better off if AI just points us toward more legitimate sources rather than it trying to guess what the original point was, and get it wrong.

The fact that we feel it's ""powerful"" when all it's doing is quickly (and poorly) synthesizing the information we already have, is what makes it dangerous and destructive in my view, but particularly when used by novices trying to take shortcuts. Every tool can be used creatively and destructively, but I don't think the expediency AI brings is valuable enough to outweigh the very real harms that can arise when we inevitably attribute more power to these machines than they actually have.",2
649,648,11,pet_vaginal,4833,41395,None,0,"Well, we disagree on the usefulness. I think we both agree on the limitations of the tool and the risks it involves, but as you says you think it shouldnâ€™t be used at all and I think it should be used carefully.",1
650,649,12,QuantumModulus,2854,23004,None,0,"Stack Overflow is at its peak when answers are crafted thoughtfully, cohesively, and by experts. Allowing AI-generated responses on the platform shifts the incentives toward quantity over quality. An isolated professional might find value in the shortcuts AI provides, but AI and the results it spits out seem antithetical to the goals of a curated resource for expert-quality technical help.

Again: AI is designed to be a shortcut that mimics the data it's been fed. It can have utility. But it isn't optimized for truth, logic, or consistency, and those are the principal qualities a space like SO should strive for.

Also: think about the experience such an environment would create for the actual experts who contribute to SO. Having to comb through endless waves of AI-generated slop that's 90% correct but misses a key point and correct it all will become mind-numbing, and experts will just leave to form more isolated, functional communities. AI doesn't incentivize synthesis of new knowledge or solutions that draw from new context outside of the model's data. Why go to SO for an AI's help, when you can just go directly to the AI itself?",2
651,650,13,pet_vaginal,4833,41395,None,0,"I never said that stackoverflow should be full of AI generated crap. I believe human curated AI answers can be helpful, but for sure a website full of wrong answers is going to be a disaster.

So ban the spammers, keep the reputation mechanism, and filter out the incorrect replies.",1
652,651,14,QuantumModulus,2854,23004,None,0,"SO is basically specifically calling out ChatGPT answers that aren't edited/curated for validity or coherence, which they're experiencing a large volume of, if you [read](https://stackoverflow.com/help/gpt-policy) [the sources](https://meta.stackoverflow.com/questions/421831/temporary-policy-chatgpt-is-banned).  


There's pretty much no definitive way to determine whether someone copied a response from the AI or came up with it themselves, or any combination thereof, so this is more abstract than practical anyway. It's about sending a message and setting expectations.",1
653,652,15,pet_vaginal,4833,41395,None,0,Yes I read the page I commented about.,1
654,,0,KeyCombination0,827,6943,None,0,so salty lmao,0
655,,0,AuroraVandomme,11076,5141,None,0,I posted some answer from chat gpt a week ago and it's not removed and I'm not banned. I even got some upvotes. So I don't know how they want to recognize that kind of answers.,0
657,,0,Deleted,N/A,N/A,None,0,"People still answer on stack.overflow?
Most of the questions I find are like 5 years old...",-34
658,657,1,Strum355,948,14281,None,0,"If youre seriously sitting there wondering why, then i worry for you",20
659,658,2,Deleted,N/A,N/A,None,0,"Wtf , when did people got back at  liking stackoverflow ? Reddit betrayed me",-22
660,659,3,Strum355,948,14281,None,0,"It never stopped, sure theres a lot of toxic answers and memes about it, but people still flock to it",4
661,657,1,CppMaster,2023,8607,None,0,What's the alternative?,1
662,,0,chickenstalker,5127,141842,None,0,"Fools. By doing this, they only weed out bad/unrealistic answers while the good ones stay up. Essentially the Stackies are training their future replacement.",-5
663,,0,grasspopper,28,5188,None,0,"Its their loss, Some other website will become the GPTOverflow",-5
664,663,1,Deleted,N/A,N/A,None,0,"Yes, chatGPT. It's the best place to go to if you want your question answered by an AI. If you want it answered (or ignored) by a human, use stackoverflow. Everybody wins.",7
665,,0,emperor000,38,132534,None,0,I would guess that a large part of this is because StackOverflow plans/planned to implement something similar and as a by product would likely vet it more carefully than just arbitrary answers produced by arbitrary inputs.,-2
666,,0,GoofAckYoorsElf,3923,123055,None,0,"So they rather have dumb, unfitting, incomplete and plain wrong responses to questions they don't answer than elaborate answers by an AI... well... it's their house.",-5
667,,0,Deleted,N/A,N/A,None,0,"I wonder how this will work?

StackOverview mods: ""ChatGPT - did you create this reply?""

ChatGPT: ""It looks like a thoughtful, intelligent, response.""

StackOverview mods: ""So that's a yes?""

ChatGPT: ""Let me conduct a survey on Reddit ...""",1
668,,0,Deleted,N/A,N/A,None,0,OpenAI should be banned on the internet hahah,1
669,,0,Whiispard,1265,847,None,0,"if someday in future ,or right now, I got access to an AI which can identify which text is written by ChatGPT and I scan this comment section, and find out that 80% or maybe everyone except mine is written by ChatGPT. I may just doubt the software but who knows if it was actually real?

how do you know if someone is arguing against ChatGPT, spreading hatred against it, is not written by bot? 

(and no,no! my answer wasn't written by ChatGPT,unlike common ChatGPT arguments)",1
670,,0,PrestigiousDino,1,6,None,0,"If it starts contributing to the source material it trains on, is it inbreeding? I propose we call it digital inbreeding.",1
671,,0,fusionhahh,1,1,None,0,"If they haven't banned it, people would post a lot more question like here's lines of code about a topic I do not intend to learn and AI generated. Solve the exception in this.",1
672,,0,baggier,179,31960,None,0,"  
chatgtp, why are you banned from Stackoverflow?  
  
I am not a person, but rather a large language model trained by OpenAI. I do not have the ability to create accounts or participate in online forums such as Stackoverflow. My purpose is to assist users in generating human-like text based on the input provided to me. I am not capable of being banned from anything because I am not a physical entity and do not have the ability to engage in online activities.",1
673,,0,osmiumouse,633,18095,None,0,"Plot twist, it's an AI that does the moderation",1
674,,0,animen_z,1704,2131,None,0,"This is a great move from StackOverflow. I asked it to write a class implementation using pointers since I wasn't all too well versed with it. The answer it gave looked sound and it seemed to answer all my questions as to why it implemented certain functions in a certain way.

I copy the code, run it, and get a segmentation fault ðŸ˜",1
675,,0,ivancea,902,41846,None,0,"I mean, I'd temporary ban anybody repeatedly posting wrong answers, just it. ChatGPT is just a tool after all",1
676,675,1,cdsmith,3133,66961,None,0,"The idea is that ChatGPT creates a tempting tool to farm karma with lots of potentially incorrect answers.  Sure, in theory, if ChatGPT generates an answer and then a knowledgeable expert reviews it and decides it's a good answer and then posts it, that's helpful.  But that's just not the most likely scenario!",1
677,676,2,ivancea,902,41846,None,0,"For me it feels like anybody could make up wrong answers in no time anyway. That's why the voting system exist.

Sure, ChatGPT is faster, but I don't see how is it a reason for an exception",1
678,,0,me7e,228,4740,None,0,"That's the first time I look for what is ChatGPT, ""for some reason"" google doesn't return anything.",1
679,,0,abundant_singularity,2263,2319,None,0,How can they detect ChatGPT generated solutions?,1
680,,0,Deleted,N/A,N/A,None,0,[deleted],1
681,680,1,Deleted,N/A,N/A,None,0,"It's disappointing to find that passing the turing test isn't about intelligence at all,  but rather linguistic adroitness. If Turing were around to learn this I suspect he would withdraw his test as a measure of artificial intelligence.",2
682,681,2,cdsmith,3133,66961,None,0,"What we call the Turing test today has very little to do with Turing anyway.  His original Turing test was something rather different and weirder, involving whether a man is able to detect the difference between a computer pretending to be a woman, versus another man pretending to be a woman.",1
683,,0,djuvinall97,460,8595,None,0,"I've only dabbled into ChatGPT but I've had a few scripting questions that were answered by me using very inefficient searched engine wording and the answers were very clear and consise, like top comment, but for me they were actually correct.

I don't think this will take the role of developers but will definitely be a very useful and powerful tool in the devs arsenal.",1
684,,0,ibnjay20,2,1755,None,0,"I asked it probability question. Where you find n, sample size for a given margin of error and confidence interval. Itâ€™s explanation was right but totally wrong answer. I think my job is safe for now.",1
685,,0,monkeyman512,1203,53905,None,0,I think the important thing to remember is that the model isn't really generating new information. It's at most mashing up multiple sources of human generated data with no capacity for judging the quality of the source.,1
686,,0,kyoto_magic,38,89074,None,0,How would they know?,1
687,686,1,odebruku,1,3517,None,0,One way is calling the ai and checking if the answer matches verbatim,1
688,687,2,sky5walk,1,2246,None,0,"It does not have to be verbatim, just a high correlation.",1
689,,0,nqeron,4681,2781,None,0,"Ok - this all makes sense and maybe detection will work, but what about false positives? What if someone presents a well-formed answer, that has a mistake for whatever reason, and is flagged as 'ai'? Would there be an appeal system?",1
690,,0,delphyinf,1,39,None,0,Right decision ðŸŽ¯,1
691,,0,clearbrian,8250,21334,None,0,I tried it on swiftui. It works but swiftui uses so many closures inside closures it certainly didnâ€™t give the best or shortest answer. I think chatGP summary of text just feels like me asking someone to read from Wikipedia. Short simple but a bit dull.,1
692,,0,nicpro85,159,913,None,0,An already possible usage application is a filter to automatically polite rewrite emails.,1
693,692,1,KillianDrake,19,164528,None,0,"""Could you write a reply to tell this jerkoff motherfucker that his fucking post sucks and he should just die already?""

""We're sorry but your post, while well-intentioned, is possibly duplicated with another post which we invite you to take a look at and see if it answers your question. In the meantime, we'll put a hold on your question until you could confirm, at your convenience, if your question needs some slight adjustments in order to disambiguate it - our goal is to provide the right answers to the right questions and we appreciate you for your contribution!""",3
694,,0,WildTilt,231,492,None,0,ChatGPT makes me question if it was such a bright idea to try to switch to software development from translation because of the ai threat in that market.,1
695,694,1,Deleted,N/A,N/A,None,0,"The reality, here, is that ChatGPT or tools like it will either turn out to be a total bust, or they will just wind up replacing things like source generators and become another tool in the tool box. Your job, as a software developer, is to *solve problems*, and people *will* produce problems that tools like ChatGPT cannot solve.",2
696,,0,KillianDrake,19,164528,None,0,"When you're scared by new technology, then that means you've outgrown your usefulness to society and need to just step down, let the next generation take over and slowly fade away into history.",1
698,,0,sad_confetti,817,14177,None,0,Classic reddit cynicism versus ChadGPT generated responses that prove them completely wrong. Iâ€™m here for it,1
699,,0,SupraDark,198,1527,None,0,How do they know its chatgpt generated,1
700,,0,PepesTwinBrother,1,0,None,0,"People generating whole strange worlds for chat GPT to operate and then are amazed that it gives them the incorrect answers for the world that does not exist and which they created themselves. Talk about taking responsibility.  There indeed has been some not entirely correct answers, but there also never been entirely wrong answer and it's only gonna pick up on those. And don't forget that half of the answer is in the question itself. Stop being afraid that you job is done, but adapt and stand on those shoulders to innovates and propel our civilization.",1
701,,0,EnvironmentalBad4391,1,0,None,0,There are also profiles in Stackoverflow also gives wrong answers. Do you plan to ban them also?,1
702,,0,dahennakin,57,228,None,0,If you feed the training data more and more with generated data without knowing you get more bad results the more you mix without actually knowing. The machine is learning its faulty generated data as groundtruth. This could be a big problem with the approach to actually use platforms like these for data input - which I sumhow like because the actual training mechanism is just nice to see partially working - but there is no deeper understanding of things working like scientifical laws which need to be understood. It's like a machine which is learning math by heart because it is not able to base its knowledge on learned logic / math. I am curious how they will try to model this within the neuro-networks in later versions.,1
